[["概述.html", "非参数统计 第 1 章 概述 1.1 习题1: (1.5 数据可视化，查看对总体分布的假设是否合理) 1.2 数据变换（Box-Cox变换） 1.3 2.(1) 1.4 2.(2)", " 非参数统计 Sifan Liu, TJUFE 2022-08-03 第 1 章 概述 1.1 习题1: (1.5 数据可视化，查看对总体分布的假设是否合理) 直方图 箱线图 QQ图(quantile-quantile plots): 由从小到大排序的样本点和标准总体分布的分位点(\\(\\Phi^{-1}[(i-3/8)/(n+1/4)]\\))所作散点图 x=rnorm(500) y=rexp(500,1) par(mfrow=c(2,3)) hist(x,main=&quot;a. Histogram of x&quot;) boxplot(x,main=&quot;b. Boxplot of x&quot;) qqnorm(x,main=&quot;c. Normal Q-Q Plot of x&quot;) hist(y,main=&quot;d. Histogram of y&quot;) boxplot(y,main=&quot;e. Boxplot of y&quot;) qqnorm(y,main=&quot;f. Normal Q-Q Plot of y&quot;) 1.2 数据变换（Box-Cox变换） \\[y= \\left\\{ \\begin{align} (x^\\lambda-1)/\\lambda &amp;&amp; \\lambda \\neq 0; \\\\ log x &amp;&amp; \\lambda=0. \\end{align} \\right.\\] x = exp(rnorm(5000,1)) lambda = c(1.5,1,0.75,0.4,0,-0.25,-0.5,-0.75) Box_Cox &lt;- function(x,lambda){ if(lambda==0){return(log(x))} else{return((x^lambda-1)/lambda)} } par(mfrow=c(2,4)) for(i in 1:8){ hist(Box_Cox(x,lambda[i]),main=paste0(expression(lambda),&quot;=&quot;,lambda[i])) } 1.3 2.(1) pnorm(2.1,1000,1) #H1为真时，X&lt;2.1的概率 ## [1] 0 pnorm(2.1,low=F) #H0为真时，X&gt;2.1的概率 ## [1] 0.01786442 1-pnorm(2.1) ## [1] 0.01786442 1.4 2.(2) x=c(rep(100,6), rep(99,4)); y=c(50,0) t.test(x,mu=100,alt=&quot;less&quot;) ## ## One Sample t-test ## ## data: x ## t = -2.4495, df = 9, p-value = 0.01839 ## alternative hypothesis: true mean is less than 100 ## 95 percent confidence interval: ## -Inf 99.89935 ## sample estimates: ## mean of x ## 99.6 t.test(y,mu=100,alt=&quot;less&quot;) ## ## One Sample t-test ## ## data: y ## t = -3, df = 1, p-value = 0.1024 ## alternative hypothesis: true mean is less than 100 ## 95 percent confidence interval: ## -Inf 182.8438 ## sample estimates: ## mean of x ## 25 "],["单样本位置参数.html", "第 2 章 单样本位置参数 2.1 引入的例子：楼盘均价 2.2 2.1 符号检验 Sign Test 2.3 2.2 Wilcoxon符号秩检验(Wilcoxon Sign Rank) 2.4 2.3 正态记分检验*(normal score) 2.5 2.4 Cox-Stuart趋势检验* 2.6 2.5 随机性的游程检验*", " 第 2 章 单样本位置参数 2.1 引入的例子：楼盘均价 ##数据 x1 &lt;- c(36, 32, 31, 25, 28, 36, 40, 32, 41, 26, 35, 35, 32, 87, 33, 35) ##单样本t检验 t.test(x1,mu=37) ## ## One Sample t-test ## ## data: x1 ## t = -0.14123, df = 15, p-value = 0.8896 ## alternative hypothesis: true mean is not equal to 37 ## 95 percent confidence interval: ## 28.95415 44.04585 ## sample estimates: ## mean of x ## 36.5 ##直方图 hist(x1) ##向量计算 x1-37 ## [1] -1 -5 -6 -12 -9 -1 3 -5 4 -11 -2 -2 -5 50 -4 -2 (x1&lt;37) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE ## [13] TRUE FALSE TRUE TRUE ##sign test library(BSDA) ## Loading required package: lattice ## ## Attaching package: &#39;BSDA&#39; ## The following object is masked from &#39;package:datasets&#39;: ## ## Orange SIGN.test(x1,md=37,alternative=&quot;two.sided&quot;,conf.level=0.95) ## ## One-sample Sign-Test ## ## data: x1 ## s = 3, p-value = 0.02127 ## alternative hypothesis: true median is not equal to 37 ## 95 percent confidence interval: ## 31.51725 36.00000 ## sample estimates: ## median of x ## 34 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.9232 32.0000 36 ## Interpolated CI 0.9500 31.5173 36 ## Upper Achieved CI 0.9787 31.0000 36 检验统计量\\(S=\\min\\{S^+,S^-\\}\\),\\(S^+=\\#\\{X&gt;median\\}\\),\\(S^-=\\#\\{X&lt;median\\}\\); \\(n=s^++s^-\\); p值=\\(2P(S\\leq s)\\)，\\(S \\sim B(n,0.5)\\) 2*(1-pbinom(12,16,0.5)) #2P(S&gt;=n-s)=2P(S&gt;=13)=2[1-P(S&lt;=12)] ## [1] 0.02127075 2*pbinom(3,16,0.5) #2P(S&lt;=s)=2P(S&lt;=3) ## [1] 0.02127075 ##wilcoxon signed rank test wilcox.test(x1,mu=37,alternative=&quot;two.sided&quot;) ## Warning in wilcox.test.default(x1, mu = 37, alternative = &quot;two.sided&quot;): cannot ## compute exact p-value with ties ## ## Wilcoxon signed rank test with continuity correction ## ## data: x1 ## V = 29.5, p-value = 0.04904 ## alternative hypothesis: true location is not equal to 37 2.2 2.1 符号检验 Sign Test 2.2.1 2.1.1. 广义符号检验 2.2.1.1 SIGN.test只能处理中位数的问题 expens &lt;- read.table(file=&quot;data/ExpensCities.TXT&quot;) SIGN.test(expens$V1,md=64,alternative=&quot;two.sided&quot;,conf.level=0.95) ## ## One-sample Sign-Test ## ## data: expens$V1 ## s = 43, p-value = 0.09592 ## alternative hypothesis: true median is not equal to 64 ## 95 percent confidence interval: ## 63.28094 77.04644 ## sample estimates: ## median of x ## 67.7 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.9432 63.5000 76.8000 ## Interpolated CI 0.9500 63.2809 77.0464 ## Upper Achieved CI 0.9681 62.7000 77.7000 2.2.1.2 自定义函数：广义符号检验 sign.test=function(x,p,q0){ s1=sum(x&lt;q0);s2=sum(x&gt;q0);n=s1+s2 p1=pbinom(s1,n,p);p2=1-pbinom(s1-1,n,p) if (p1&gt;p2){ m1=&quot;One tail test: H1: Q&lt;q0&quot; } else{ m1=&quot;One tail test: H1: Q&gt;q0&quot; } p.value=min(p1,p2);m2=&quot;Two tails test&quot;;p.value2=2*p.value if (q0==median(x)){ p.value=0.5;p.value2=1 } list(Sign.test1=m1, p.values.of.one.tail.test=p.value, p.value.of.two.tail.test=p.value2) } sign.test(expens$V1,0.5,64) ## $Sign.test1 ## [1] &quot;One tail test: H1: Q&gt;q0&quot; ## ## $p.values.of.one.tail.test ## [1] 0.04796182 ## ## $p.value.of.two.tail.test ## [1] 0.09592363 sign.test(expens$V1,0.25,64) ## $Sign.test1 ## [1] &quot;One tail test: H1: Q&lt;q0&quot; ## ## $p.values.of.one.tail.test ## [1] 0.005151879 ## ## $p.value.of.two.tail.test ## [1] 0.01030376 \\(H_0:Q_{0.25} \\geq 64 \\leftrightarrow H_1:Q_{0.25} &lt; 64\\); 检验统计量\\(S^-=\\#\\{X&lt;q_0\\}\\),\\(q_0=64\\),\\(n=s^++s^-\\); 如果\\(Q_{0.25} = q_0\\)，应有\\(S^- \\sim B(n,0.25)\\); 如果\\(s^-\\)的值较大，说明较多的值比\\(q_0\\)小，因此\\(Q_{0.25} &lt; q_0\\); 此时，p值\\(=P(S\\geq s^-)=1-P(S\\leq s^--1)\\)，\\(S \\sim B(n,0.25)\\) 2.2.2 2.1.2 分位点的置信区间 2.2.2.1 中位数的置信区间 tax &lt;- read.table(file=&quot;data/tax.TXT&quot;) (tax &lt;- sort(tax$V1)) ## [1] 1.00 1.35 1.99 2.05 2.05 2.10 2.30 2.61 2.86 2.95 2.98 3.23 3.73 4.03 4.82 ## [16] 5.24 6.10 6.64 6.81 6.86 7.11 9.00 SIGN.test(tax,alternative=&quot;two.sided&quot;,conf.level=0.95)$Confidence.Intervals ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.9475 2.3000 5.2400 ## Interpolated CI 0.9500 2.2861 5.2999 ## Upper Achieved CI 0.9831 2.1000 6.1000 2.2.2.2 自定义函数（一）：中位数的置信区间 mci=function(x,alpha=0.05){ n=length(x) b=0 i=0 while(b&lt;=alpha/2&amp;i&lt;=floor(n/2)){ b=pbinom(i,n,.5); k1=i;k2=n-i+1; a=2*pbinom(k1-1,n,.5); i=i+1 } z=c(k1,k2,a,1-a); z2=&quot;Entire range!&quot; if(k1&gt;=1){ out=list(Confidence.level=1-a,CI=c(x[k1],x[k2])) } else{ out=list(Confidence.level=1-2*pbinom(0,n,.5),CI=z2) } out } mci(tax,alpha=0.05) ## $Confidence.level ## [1] 0.9830995 ## ## $CI ## [1] 2.1 6.1 2.2.2.3 自定义函数（二）：中位数的置信区间 mci2=function(x,alpha=0){ n=length(x);q=.5 m=floor(n*q);s1=pbinom(0:m,n,q);s2=pbinom(m:(n-1),n,q,low=F); ss=c(s1,s2);nn=length(ss);a=NULL; for(i in 0:m){ b1=ss[i+1];b2=ss[nn-i];b=b1+b2;d=1-b; if((b)&gt;1)break a=rbind(a,c(b,d,x[i+1],x[n-i]))} if(a[1,1]&gt;alpha){ out=&quot;alpha is too small, CI=All range&quot; } else{ for(i in 1:nrow(a)){ if(a[i,1]&gt;alpha){out=a[i-1,];break} } } out } mci2(tax,alpha=0.05) ## [1] 0.01690054 0.98309946 2.10000000 6.10000000 2.2.2.4 分位数的置信区间 qci=function(x,alpha=0.05,q=.25){ x&lt;-sort(x);n=length(x);a=alpha/2;r=qbinom(a,n,q); s=qbinom(1-a,n,q);CL=pbinom(s,n,q)-pbinom(r-1,n,q) if (r==0) lo&lt;-NA else lo&lt;-x[r] if (s==n) up&lt;-NA else up&lt;-x[s+1] list(c(&quot;lower limit&quot;=lo,&quot;upper limit&quot;=up, &quot;1-alpha&quot;=1-alpha,&quot;true conf&quot;=CL)) } qci(tax,0.05,0.25) ## [[1]] ## lower limit upper limit 1-alpha true conf ## 1.3500000 2.9800000 0.9500000 0.9751605 qci(tax,0.06,0.25) ## [[1]] ## lower limit upper limit 1-alpha true conf ## 1.350000 2.950000 0.940000 0.955626 2.3 2.2 Wilcoxon符号秩检验(Wilcoxon Sign Rank) 2.3.1 2.2.1 检验 euroalc &lt;- read.table(file=&quot;data/EuroAlc10.TXT&quot;) y &lt;- as.numeric(euroalc[1,]) y ## [1] 4.12 5.81 7.63 9.74 10.39 11.92 12.32 12.89 13.54 14.45 wilcox.test(y-8) ## ## Wilcoxon signed rank exact test ## ## data: y - 8 ## V = 46, p-value = 0.06445 ## alternative hypothesis: true location is not equal to 0 wilcox.test(y-8,exact = F) ## ## Wilcoxon signed rank test with continuity correction ## ## data: y - 8 ## V = 46, p-value = 0.06655 ## alternative hypothesis: true location is not equal to 0 wilcox.test(y-8,alt=&quot;greater&quot;) ## ## Wilcoxon signed rank exact test ## ## data: y - 8 ## V = 46, p-value = 0.03223 ## alternative hypothesis: true location is greater than 0 wilcox.test(y-12.5,alt=&quot;less&quot;) ## ## Wilcoxon signed rank exact test ## ## data: y - 12.5 ## V = 11, p-value = 0.05273 ## alternative hypothesis: true location is less than 0 2.3.2 2.2.2 置信区间 2.3.2.1 Walsh平均 walsh=NULL; for(i in 1:10){ for(j in i:10){ walsh=c(walsh,(y[i]+y[j])/2) } } walsh=sort(walsh) walsh ## [1] 4.120 4.965 5.810 5.875 6.720 6.930 7.255 7.630 7.775 8.020 ## [11] 8.100 8.220 8.505 8.685 8.830 8.865 9.010 9.065 9.285 9.350 ## [21] 9.675 9.740 9.775 9.975 10.065 10.130 10.260 10.390 10.585 10.830 ## [31] 11.030 11.040 11.155 11.315 11.355 11.640 11.640 11.920 11.965 12.095 ## [41] 12.120 12.320 12.405 12.420 12.605 12.730 12.890 12.930 13.185 13.215 ## [51] 13.385 13.540 13.670 13.995 14.450 2.3.2.2 利用Walsh平均构造置信区间 (k &lt;- qsignrank(0.025,10)) ## [1] 9 N &lt;- length(walsh) c(walsh[k+1],walsh[N-k]) ## [1] 8.02 12.73 wilcox.test(y,conf.int = T)$conf.int ## [1] 7.775 12.890 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 2.3.3 simulation study Which of the two tests, the signed-rank Wilcoxon or the t-test, is the more powerful? power_comparison &lt;- function(mu){ n = 30; df = 2; nsims = 10000; collwil = rep(0,nsims) collt = rep(0,nsims) for(i in 1:nsims){ x = rt(n,df) + mu wil = wilcox.test(x) collwil[i] = wil$p.value ttest = t.test(x) collt[i] = ttest$p.value } powwil = rep(0,nsims); powwil[collwil &lt;= .05] = 1 powerwil = sum(powwil)/nsims powt = rep(0,nsims); powt[collt&lt;= .05] = 1 powert = sum(powt)/nsims list(powerwil,powert) } power_comparison(0) ## [[1]] ## [1] 0.0501 ## ## [[2]] ## [1] 0.0405 power_comparison(0.5) ## [[1]] ## [1] 0.4585 ## ## [[2]] ## [1] 0.2902 power_comparison(1) ## [[1]] ## [1] 0.9211 ## ## [[2]] ## [1] 0.6981 2.4 2.3 正态记分检验*(normal score) 线性符号秩统计量 \\(S_n^+=\\sum_{i=1}^n a_n^+(R_i^+) I(X_i&gt;0)\\)； \\(a_n^+(i)=i\\)时，\\(S_n^+\\)为Wilcoxon符号秩统计量\\(W^+\\)； \\(a_n^+(i)=1\\)时，\\(S_n^+\\)为符号秩统计量\\(S^+\\)； 线性秩统计量 \\(S_n=\\sum_{i=1}^n c_n(i) a_n(R_i)\\)； \\(N=m+n\\),\\(a_N(i)=i\\),\\(c_N(i)=I(i&gt;m)\\),则\\(S_n\\)为两样本Wilcoxon秩和统计量; 正态记分\\(S_n=\\sum_{i=1}^n \\Phi^{-1}\\left( \\frac{R_i}{n+1} \\right)\\); 线性秩统计量的一个特例 \\(S_n=\\sum_{i=1}^n a_n^+(R_i^+) sign(X_i)=\\sum_{i=1}^n s_i\\)； 记分函数\\(a_n^+(i)=\\Phi^{-1}\\left( \\frac{n+1+i}{2n+2} \\right)=\\Phi^{-1}\\left[\\frac{1}{2} \\left( 1 + \\frac{i}{n+1} \\right) \\right]\\),非负 检验\\(H_0:Me=M_0\\),\\(X_i-M_0\\)的秩\\(r_i\\),符号正态记分\\(s_i=a_n^+(r_i) sign(X_i-M_0)=\\Phi^{-1}\\left[\\frac{1}{2} \\left( 1 + \\frac{r_i}{n+1} \\right) \\right]sign(X_i-M_0)\\) ns=function(x,m0){ x1=x-m0;r=rank(abs(x1));n=length(x) s=qnorm(.5*(1+r/(n+1)))*sign(x1); tt=sum(s)/sqrt(sum(s^2)); list(pvalue.2sided=2*min(pnorm(tt),pnorm(tt,low=F)),Tstat=tt,s=s) } ns(y,8) ## $pvalue.2sided ## [1] 0.05567649 ## ## $Tstat ## [1] 1.913559 ## ## $s ## [1] -0.6045853 -0.3487557 -0.1141853 0.2298841 0.4727891 0.7478586 ## [7] 0.9084579 1.0968036 1.3351777 1.6906216 ns(y,12.5) ## $pvalue.2sided ## [1] 0.08114229 ## ## $Tstat ## [1] -1.744096 ## ## $s ## [1] -1.6906216 -1.3351777 -1.0968036 -0.9084579 -0.7478586 -0.3487557 ## [7] -0.1141853 0.2298841 0.4727891 0.6045853 2.5 2.4 Cox-Stuart趋势检验* 判断增长或减少趋势 求差\\(D_i=x_i-x_{i+c}\\)的符号来衡量增减 像符号检验一样用到二项分布 TJair &lt;- read.table(file=&quot;data/TJAir.TXT&quot;) TJair &lt;- as.vector(t(TJair)) plot.ts(TJair,xlab=&quot;Month&quot;,ylab=&quot;Number of Passenger&quot;) D &lt;- TJair[1:54]-TJair[55:108] Splus &lt;- sum(sign(D)==1) Sminus &lt;- sum(sign(D)==1) K &lt;- min(Splus,Sminus) pbinom(K,54,.5) ## [1] 0.001919133 2.6 2.5 随机性的游程检验* 判断n重伯努利试验结果是否随机 称连在一起的0或1为游程 游程个数R的条件分布 2.6.0.1 自定义函数 runs.test0=function(y,cut=0){ if(cut!=0)x=(y&gt;cut)*1 else x=y N=length(x);k=1; for(i in 1:(N-1))if (x[i]!=x[i+1])k=k+1;r=k; m=sum(1-x);n=N-m; P1=function(m,n,k){ 2*choose(m-1,k-1)/choose(m+n,n)*choose(n-1,k-1) } P2=function(m,n,k){ choose(m-1,k-1)*choose(n-1,k)/choose(m+n,n) +choose(m-1,k)*choose(n-1,k-1)/choose(m+n,n) } r2=floor(r/2); if(r2==r/2){ pv=0;for(i in 1:r2) pv=pv+P1(m,n,i); for(i in 1:(r2-1)) pv=pv+P2(m,n,i) } else{ pv=0 for(i in 1:r2) pv=pv+P1(m,n,i) for(i in 1:r2) pv=pv+P2(m,n,i) }; if(r2==r/2) pv1=1-pv+P1(m,n,r2) else pv1=1-pv+P2(m,n,r2); z=(r-2*m*n/N-1)/sqrt(2*m*n*(2*m*n-m-n)/(m+n)^2/(m+n-1)); ap1=pnorm(z);ap2=1-ap1;tpv=min(pv,pv1)*2; list(m=m,n=n,N=N,R=r,Exact.pvalue1=pv, Exact.pvalue2=pv1,Aprox.pvalue1=ap1,Aprox.pvalue2=ap2, Exact.2sided.pvalue=tpv,Approx.2sided.pvalue=min(ap1,ap2)*2) } run02 &lt;- read.table(file=&quot;data/run02.TXT&quot;) (run02 &lt;- run02$V1) ## [1] 12.27 9.92 10.81 11.79 11.87 10.90 11.22 10.80 10.33 9.30 9.81 8.85 ## [13] 9.32 8.67 9.32 9.53 9.58 8.94 7.89 10.77 runs.test0(run02,median(run02)) ## $m ## [1] 10 ## ## $n ## [1] 10 ## ## $N ## [1] 20 ## ## $R ## [1] 3 ## ## $Exact.pvalue1 ## [1] 5.953799e-05 ## ## $Exact.pvalue2 ## [1] 0.9999892 ## ## $Aprox.pvalue1 ## [1] 0.0001185775 ## ## $Aprox.pvalue2 ## [1] 0.9998814 ## ## $Exact.2sided.pvalue ## [1] 0.000119076 ## ## $Approx.2sided.pvalue ## [1] 0.0002371551 y &lt;- factor(sign(run02-median(run02)),labels=c(0,1)) 2.6.0.2 runs.test函数 library(tseries) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo runs.test(y) ## ## Runs Test ## ## data: y ## Standard Normal = -3.6757, p-value = 0.0002372 ## alternative hypothesis: two.sided "],["双样本位置参数.html", "第 3 章 双样本位置参数 3.1 3.1 Brown-Mood中位数检验 3.2 3.2 Wilcoxon秩和检验 3.3 3.3 正态记分（normal score）检验 3.4 3.4 成对数据的检验 3.5 3.5 McNemar检验 3.6 3.6 Cohen’s Kappa系数", " 第 3 章 双样本位置参数 第一部分 两个独立总体 3.0.1 例子：零件疲劳强度测试 x &lt;- c(82, 64, 53, 61, 59, 83, 76, 55, 70, 73) y &lt;- c(80, 60, 65, 91, 86, 84, 77, 93, 75) ##wilcoxon rank sum test wilcox.test(x,y) ## ## Wilcoxon rank sum exact test ## ## data: x and y ## W = 19, p-value = 0.03499 ## alternative hypothesis: true location shift is not equal to 0 3.1 3.1 Brown-Mood中位数检验 检验两总体中位数是否相等； 计算两样本共同的中位数\\(M_{XY}\\)，用两个样本和\\(M_{XY}\\)比较后得到各个样本中大于和小于它的数目； 利用超几何分布 3.1.1 精确检验 z=read.table(&quot;data/salary.txt&quot;) (salary1 &lt;- z[,1][z[,2]==1]) #样本1 ## [1] 6864 7304 7477 7779 7895 8348 8461 9553 9919 10073 10270 11581 ## [13] 13472 13600 13962 15019 17244 (salary2 &lt;- z[,1][z[,2]==2]) #样本2 ## [1] 10276 10533 10633 10837 11209 11393 11864 12040 12642 12675 13199 13683 ## [13] 14049 14061 16079 par(mfrow=c(1,3)) #箱线图 boxplot(salary1,ylim=c(7000,17000)) boxplot(salary2,ylim=c(7000,17000)) boxplot(z[,1],ylim=c(7000,17000)) k=unique(z[,2]); # 样本编号 (m=median(z[,1])); # 中位数 ## [1] 11301 m1=NULL;m2=NULL for(i in k){ m1=c(m1,sum(z[z[,2]==i,1]&gt;m)) # 大于中位数的个数 m2=c(m2,sum(z[z[,2]==i,1]&lt;m)) # 小于等于中位数的个数 } (C=rbind(m1,m2)) ## [,1] [,2] ## m1 6 10 ## m2 11 5 ##H1:Mx&lt;My phyper(6,17,15,16) # 利用超几何分布计算概率 # phyper(a,m,n,a+b) ## [1] 0.07780674 fisher.test(C,alt=&quot;less&quot;) # 使用fisher.test函数 ## ## Fisher&#39;s Exact Test for Count Data ## ## data: C ## p-value = 0.07781 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.000000 1.166386 ## sample estimates: ## odds ratio ## 0.2848586 3.1.2 大样本近似 \\[Z=\\frac{A \\pm 0.5 -mt/N}{\\sqrt{mnt(N-t)/N^3}} \\sim N(0,1)\\] pnorm((6+.5-17*16/32)/sqrt(17*15*16*(32-16)/32^3)) ## [1] 0.07824383 \\[K=\\frac{(2A-m)^2(m+n)}{mn} \\sim \\chi^2_{(1)}\\] (K=(2*6-17)^2*(17+15)/17/15) ## [1] 3.137255 1-pchisq(K,1) # p值 ## [1] 0.0765225 3.2 3.2 Wilcoxon秩和检验 利用更多的关于样本点相对大小的信息 3.2.1 *例：Wilcoxon Test for Stochastic Ordering of Alternatives #(Esophageal Cancer). This example is based on the case control study of esophageal cancer in Ile-et-Vilaine, France (Breslow et al. 1980). These data are available in the datasets package. We test the hypothesis that alcohol consumption is the same in the two groups, using as our dataset a sample of cases and controls library(datasets) data(esoph) x1&lt;-rep(esoph$alcgp,esoph$ncases) y1&lt;-rep(esoph$alcgp,esoph$ncontrols) z1&lt;-c(x1,y1) w1&lt;-c(rep(1,length(x1)),rep(0,length(y1))) barplot(table(z1,w1),names.arg=c(&#39;Cases&#39;,&#39;Controls&#39;),legend.text=levels(esoph$alcgp)) (x1&lt;-as.numeric(x1)) ## [1] 4 1 2 2 2 2 4 4 4 4 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 ## [38] 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 ## [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [112] 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 ## [149] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 ## [186] 4 4 1 1 1 1 2 2 2 2 3 3 4 4 4 (y1&lt;-as.numeric(y1)) ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 ## [112] 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [223] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [297] 3 3 3 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [371] 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [408] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 ## [445] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 1 1 1 1 1 1 1 1 1 ## [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 ## [556] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [593] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [630] 3 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 ## [704] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [741] 3 3 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 wilcox.test(x1,y1) ## ## Wilcoxon rank sum test with continuity correction ## ## data: x1 and y1 ## W = 115612, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 3.2.2 *例： Analyses for a Shift in Location #(Generated t5-Data). The following are two samples generated from a t-distribution with 5 degrees of freedom. The true shift parameter was set at the value 8. x1&lt;-round(rt(11,5)*10+42,1) y1&lt;-round(rt(9,5)*10+50,1) sort(x1) ## [1] 32.9 35.5 36.9 37.4 39.7 41.9 51.8 53.8 54.1 58.6 67.6 sort(y1) ## [1] 33.1 44.0 44.2 45.5 47.2 50.9 63.5 65.6 79.6 wilcox.test(x1,y1,exact=TRUE) ## ## Wilcoxon rank sum exact test ## ## data: x1 and y1 ## W = 37, p-value = 0.3702 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(x1,y1,exact=FALSE,correct=FALSE) ## ## Wilcoxon rank sum test ## ## data: x1 and y1 ## W = 37, p-value = 0.3423 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(y1,x1,conf.int=TRUE) ## ## Wilcoxon rank sum exact test ## ## data: y1 and x1 ## W = 62, p-value = 0.3702 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## -7.6 15.4 ## sample estimates: ## difference in location ## 7.1 3.2.3 3.2.1 假设检验 wilcox.test(salary1,salary2,alt=&quot;less&quot;) ## ## Wilcoxon rank sum exact test ## ## data: salary1 and salary2 ## W = 69, p-value = 0.01352 ## alternative hypothesis: true location shift is less than 0 pwilcox(69,15,17) ## [1] 0.01352166 wilcox.test(salary1,salary2) ## ## Wilcoxon rank sum exact test ## ## data: salary1 and salary2 ## W = 69, p-value = 0.02704 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(salary1,salary2,exact=F) ## ## Wilcoxon rank sum test with continuity correction ## ## data: salary1 and salary2 ## W = 69, p-value = 0.02851 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(salary1,salary2,exact=F,cor=F) ## ## Wilcoxon rank sum test ## ## data: salary1 and salary2 ## W = 69, p-value = 0.02717 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(salary1,salary2,exact=F,alt=&quot;less&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: salary1 and salary2 ## W = 69, p-value = 0.01425 ## alternative hypothesis: true location shift is less than 0 wilcox.test(salary1,salary2,exact=F,alt=&quot;less&quot;,cor=F) ## ## Wilcoxon rank sum test ## ## data: salary1 and salary2 ## W = 69, p-value = 0.01358 ## alternative hypothesis: true location shift is less than 0 3.2.4 3.2.2 置信区间 (D=sort(as.vector(outer(salary1,salary2,&quot;-&quot;)))) ## [1] -9215 -8775 -8602 -8300 -8184 -7731 -7618 -7197 -7185 -6819 -6757 -6745 ## [13] -6584 -6572 -6526 -6379 -6335 -6282 -6270 -6206 -6166 -6160 -6154 -6006 ## [25] -5904 -5895 -5811 -5809 -5788 -5778 -5722 -5713 -5701 -5600 -5588 -5420 ## [37] -5371 -5338 -5335 -5304 -5222 -5198 -5176 -5165 -5000 -4896 -4863 -4851 ## [49] -4780 -4747 -4738 -4736 -4563 -4560 -4529 -4508 -4498 -4496 -4387 -4345 ## [61] -4327 -4294 -4261 -4214 -4181 -4145 -4142 -4130 -4130 -4089 -4085 -3988 ## [73] -3976 -3973 -3969 -3916 -3905 -3791 -3779 -3769 -3764 -3732 -3692 -3669 ## [85] -3646 -3614 -3610 -3579 -3533 -3516 -3498 -3430 -3413 -3412 -3403 -3360 ## [97] -3329 -3314 -3280 -3229 -3156 -3126 -3122 -3089 -3058 -3056 -3045 -2972 ## [109] -2942 -2932 -2929 -2861 -2854 -2799 -2756 -2754 -2748 -2738 -2723 -2638 ## [121] -2607 -2602 -2569 -2497 -2489 -2487 -2480 -2479 -2468 -2405 -2381 -2376 ## [133] -2372 -2311 -2285 -2185 -2172 -2121 -2117 -2102 -2072 -1967 -1945 -1928 ## [145] -1840 -1815 -1791 -1770 -1656 -1618 -1594 -1474 -1320 -1290 -1284 -1136 ## [157] -1123 -1094 -1080 -1061 -1060 -980 -939 -918 -764 -723 -714 -614 ## [169] -589 -577 -567 -560 -461 -460 -459 -449 -363 -357 -283 -263 ## [181] -211 -203 -99 -87 -83 -6 188 273 279 372 401 744 ## [193] 763 797 830 925 948 958 958 970 1048 1165 1287 1305 ## [205] 1320 1336 1432 1560 1608 1736 1820 1922 2079 2098 2207 2263 ## [217] 2344 2377 2391 2569 2635 2753 2763 2839 2939 2967 2979 3067 ## [229] 3125 3155 3183 3195 3196 3324 3329 3429 3561 3626 3686 3810 ## [241] 4045 4182 4386 4486 4569 4602 4743 5204 5380 5851 6035 6407 ## [253] 6611 6711 6968 (Wa=qwilcox(0.025,17,15)) ## [1] 76 c(D[Wa],D[17*15+1-Wa]) ## [1] -3916 -263 3.3 3.3 正态记分（normal score）检验 用正态记分代替秩 3.3.1 例子：salary w=cbind(c(salary1,salary2),c(rep(1,17),rep(2,15)));w=w[order(w[,1]),] w=cbind(w,1:32,qnorm((1:32)/(17+15+1))) m=17;n=15; Tstat = sum(w[w[,2]==1,4]) w2 = sum(w[,4]^2) S = sqrt(m*n*w2/(m+n-1)/(m+n)) Z = Tstat/S pnorm(Z) ## [1] 0.01925286 第二部分 不独立的两个总体 3.4 3.4 成对数据的检验 成对数据的差，使用符号检验、Wilcoxon符号秩检验 3.4.1 例子：实施管理前后 x2 &lt;- c(1.2,-0.6,-0.3,1.1,-0.2,-0.2,-0.8,0.3,-0.2,-0.1) library(BSDA) ## Loading required package: lattice ## ## Attaching package: &#39;BSDA&#39; ## The following object is masked from &#39;package:datasets&#39;: ## ## Orange SIGN.test(x2,md=0,altervative=&quot;two.sided&quot;,conf.level=0.95) ## ## One-sample Sign-Test ## ## data: x2 ## s = 3, p-value = 0.3438 ## alternative hypothesis: true median is not equal to 0 ## 95 percent confidence interval: ## -0.5026667 0.8404444 ## sample estimates: ## median of x ## -0.2 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.8906 -0.3000 0.3000 ## Interpolated CI 0.9500 -0.5027 0.8404 ## Upper Achieved CI 0.9785 -0.6000 1.1000 wilcox.test(x2,md=0,altervative=&quot;two.sided&quot;,conf.level=0.95) ## Warning in wilcox.test.default(x2, md = 0, altervative = &quot;two.sided&quot;, conf.level ## = 0.95): cannot compute exact p-value with ties ## ## Wilcoxon signed rank test with continuity correction ## ## data: x2 ## V = 24.5, p-value = 0.7982 ## alternative hypothesis: true location is not equal to 0 3.4.2 例子：病人血压 bp &lt;- read.table(&quot;data/bp.txt&quot;) x &lt;- bp$V1 y &lt;- bp$V2 wilcox.test(x,y,paired = T,alt=&quot;greater&quot;) ## ## Wilcoxon signed rank exact test ## ## data: x and y ## V = 49, p-value = 0.01367 ## alternative hypothesis: true location shift is greater than 0 psignrank(sum(rank(x-y)[x&lt;y]),length(x)) ## [1] 0.01367188 3.5 3.5 McNemar检验 配对的二元取值数据 二维列联表，卡方检验统计量 是Cochran’s Q检验的特例 3.5.1 精确检验 Cochran=function(x){ Xpchs=function(n=7,k=5){ #output(n_1,..,n_k)-all possible combination with n_1+...+n_k=n temp=cbind(n:0,0:n); if (k&gt;=3){ for (j in 3:k){ a1=temp[,1:(j-2)];a2=temp[,j-1];temp0=NULL; for (i in 1:length(a2)){ if (j==3) temp0=rbind(temp0,cbind(rep(a1[i],a2[i]+1),a2[i]:0,0:a2[i])) if (j&gt;3) temp0=rbind(temp0,cbind(matrix(rep(a1[i,],a2[i]+1), ncol=j-2,byrow=T),a2[i]:0,0:a2[i])) } temp=temp0 } } temp } Xpchs2=function(n=4,k=2){ #output: all 0 and 1 columns, with n-k 0s and k- 1s columns Xchoose=function(n=4,k=2){ if (k==0) aa=NULL if (k&gt;=1){ aa=matrix(1:n,ncol=1);m=0; if(k&gt;1){ for(i in 2:k){ m=m+1;m1=nrow(aa); aa=cbind(matrix(rep(aa,each=n),ncol=m),rep(1:n,m1)) aa=aa[(aa[,m+1]&gt;aa[,m]),] } } }; aa }; e01=Xchoose(n,k) temp=matrix(0,nrow=nrow(e01),ncol=n); for (j in 1:nrow(temp)){ if (k==1) temp[j,e01[j]]=1 if (k&gt;1) temp[j,e01[j,]]=1 }; temp } n=nrow(x);k=ncol(x); L=apply(x,1,sum);R=apply(x,2,sum);N=sum(R); Q0=(k*(k-1)*sum((R-mean(R))^2))/(k*N-sum(L^2)); Ni=NULL; for (i in 1:k-1) Ni=c(Ni,sum(L==i)); Ni=Ni[-1]; eye0=Xpchs2(k,1);temp0=Xpchs(Ni[1],nrow(eye0));Ri0=temp0%*%eye0; prob0=factorial(Ni[1])/apply(factorial(temp0),1,prod)*(1/nrow(eye0))^(Ni[1]); if (length(Ni)&gt;1){ for (i in 2:length(Ni)){ eye1=Xpchs2(k,i); temp1=Xpchs(Ni[i],nrow(eye1)); Ri1=temp1%*%eye1; prob1=factorial(Ni[i])/apply(factorial(temp1),1,prod)*(1/nrow(eye1))^(Ni[i]) Ri0=matrix(rep(t(Ri0),nrow(Ri1)),byrow=T,ncol=k)+ matrix(rep(Ri1,each=nrow(Ri0)),ncol=k) prob0=rep(prob0,length(prob1))*rep(prob1,each=length(prob0)) } } xa=k*(k-1)*apply((Ri0-apply(Ri0,1,mean))^2,1,sum)/(k*N-sum(L^2)) nn=length(xa);xa0=sort(unique(xa));xacnt=NULL; for (i in 1:length(xa0)) xacnt=c(xacnt,length(xa[xa==xa0[i]])); plot(xa0,xacnt/nn,cex=0.5,ylab=&quot;density function&quot;,xlab=&quot;value of Cochran statistics&quot;); for (i in 1:length(xa0)){ points(c(xa0[i],xa0[i]),c(xacnt[i]/nn,0),type=&quot;l&quot;,lwd=2) } list(unique(xa),cbind(rbind(t(x),L),c(R,N)),Q=Q0, Exactp=sum(prob0[(xa&gt;=Q0)]),pvalue=pchisq(Q0,k-1,low=F)) } treat=read.table(&quot;data/athletefootp.txt&quot;); Cochran(treat[,-1]) ## [[1]] ## [1] 24.0000000 20.1666667 16.6666667 13.5000000 10.6666667 8.1666667 ## [7] 6.0000000 4.1666667 2.6666667 1.5000000 0.6666667 0.1666667 ## [13] 0.0000000 ## ## [[2]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## V2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 ## V3 1 1 1 1 1 1 0 0 0 0 1 1 1 1 ## L 2 2 2 2 2 2 1 1 1 1 1 1 1 1 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## V2 0 0 0 0 0 0 0 0 0 0 0 0 ## V3 1 1 1 1 1 1 1 1 1 1 1 1 ## L 1 1 1 1 1 1 1 1 1 1 1 1 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## V2 0 0 0 0 0 0 0 0 0 0 0 0 ## V3 1 1 1 1 0 0 0 0 0 0 0 0 ## L 1 1 1 1 0 0 0 0 0 0 0 0 ## [,39] [,40] [,41] ## V2 0 0 10 ## V3 0 0 26 ## L 0 0 36 ## ## $Q ## [1] 10.66667 ## ## $Exactp ## [1] 0.00154388 ## ## $pvalue ## [1] 0.001090835 3.5.2 大样本近似 x=read.table(&quot;data/athletefootp.txt&quot;); x=x[,-1]; n12=sum(x[((x[,1]==0)&amp;(x[,2]==1)),]) n21=sum(x[((x[,1]==1)&amp;(x[,2]==0)),]) McNemar=(n12-n21)^2/(n12+n21); pvalue=1-pchisq(McNemar,df=1) list(McNemar=McNemar,pvaluetwosided=pvalue) ## $McNemar ## [1] 10.66667 ## ## $pvaluetwosided ## [1] 0.001090835 3.6 3.6 Cohen’s Kappa系数 度量两位评估者之间评估一致性的指标 x=read.table(&quot;data/music.txt&quot;); w=matrix(x[,3],byrow=T,ncol=2); I=nrow(w);n=sum(w);w=w/n; pa=sum(diag(w)); pe=sum(apply(w,1,sum)*apply(w,2,sum)) (kap=(pa-pe)/(1-pe)) ## [1] 0.5098039 A=sum(diag(w)*(1-(apply(w,1,sum)+apply(w,2,sum))*(1-kap))^2) tempB=matrix(rep(apply(w,1,sum),I)+rep(apply(w,2,sum),each=I),byrow=T,ncol=I) diag(tempB)=0; B=(1-kap)^2*sum(w*tempB^2) CC=(kap-pe*(1-kap))^2; ASE=sqrt((A+B-CC)/(1-pe)^2/n) list(kappa=kap,ASE=ASE,CI=c(kap-1.96*ASE,kap+1.96*ASE)) ## $kappa ## [1] 0.5098039 ## ## $ASE ## [1] 0.08133101 ## ## $CI ## [1] 0.3503951 0.6692127 "],["多样本位置参数.html", "第 4 章 多样本位置参数 4.1 4.1 Kruskal-Wallis秩和检验 4.2 4.2 正态记分检验 4.3 4.3 Jonckheere-Terpstra检验 4.4 4.5 完全区组设计：Friedman秩和检验 4.5 4.6 Kendall协同系数检验 4.6 4.7 Cochran检验 4.7 4.8 Page检验 4.8 4.9 Durbin检验", " 第 4 章 多样本位置参数 单因素问题，独立样本 4.1 4.1 Kruskal-Wallis秩和检验 类比于单因素方差分析 不依赖于正态假设和方差齐性假设 Wilcoxon秩和检验的推广 4.1.1 例：训练方式 A &lt;- c(60, 75, 62, 76, 73, 98, 86) B &lt;- c(72, 52, 68, 82, 74, 64, 87) C &lt;- c(61, 85, 78, 66, 70, 59, 69, 79) D &lt;- c(63, 58, 65, 71, 84, 77, 80, 89) ##kruskal-wallis test kruskal.test(list(A,B,C,D)) ## ## Kruskal-Wallis rank sum test ## ## data: list(A, B, C, D) ## Kruskal-Wallis chi-squared = 0.55369, df = 3, p-value = 0.9069 KW.test=function(m1=5,m2=5,m3=4,Hvalue=9.4114){ # this program is for m1=5, m2=5, and m3 can be any integer m&lt;-m1+m2+m3; Jh5=function(m){ a&lt;-rep(0,5) for (i in 1:(m-4)){ for (j in (i+1):(m-3)){ for (k in (j+1):(m-2)){ for (l in (k+1):(m-1)){ for (f in (l+1):m){a&lt;-rbind(a,c(i,j,k,l,f))} } } } } a[2:nrow(a),] } JTid1&lt;-Jh5(m1+m2+m3); n1&lt;-nrow(JTid1); JTid2&lt;-Jh5(m2+m3); n2&lt;-nrow(JTid2); nn&lt;-n1*n2; const&lt;-1:m; y&lt;-0 for (i in 1:n1){ for (j in 1:n2){ temp1&lt;-c(JTid1[i,]); temp2&lt;-(const[-temp1])[c(JTid2[j,])]; temp3&lt;-const[-c(temp1,temp2)]; y&lt;-c(y,12/(m*(m+1))*((sum(temp1))^2/m1+(sum(temp2))^2/m2+(sum(temp3))^2/m3)-3*(m+1)) } } y&lt;-y[2:(nn+1)]; pvalue&lt;-(sum(y&gt;=Hvalue))/nn; y&lt;-sort(y);aaa&lt;-aa&lt;-y[1];tempc&lt;-1 for (i in 2:nn){ if((y[i]-aa)&gt;10^{-12}){ aaa&lt;-c(aaa,y[i]);aa&lt;-y[i];tempc&lt;-c(tempc,1-(i-1)/nn) } } out&lt;-cbind(aaa,tempc);z=seq(0,12,0.1); par(mfrow=c(1,2)) hist(y,main=&quot;(1) Kruskal-Wallis检验精确分布直方图&quot;) plot(z,dchisq(z,df=2),type=&quot;l&quot;,main=&quot;(2) 自由度为2的chisq分布密度函数&quot;) list(c(&quot;(m1,m2,m3)&quot;=c(m1,m2,m3),&quot;H&quot;=Hvalue,&quot;pval&quot;=pvalue),out) } KW.test() ##time-consuming ## [[1]] ## (m1,m2,m3)1 (m1,m2,m3)2 (m1,m2,m3)3 H pval ## 5.000000000 5.000000000 4.000000000 9.411400000 0.001347858 ## ## [[2]] ## aaa tempc ## [1,] 0.005714286 1.000000e+00 ## [2,] 0.020000000 9.938078e-01 ## [3,] 0.042857143 9.878772e-01 ## [4,] 0.051428571 9.759843e-01 ## [5,] 0.085714286 9.698635e-01 ## [6,] 0.111428571 9.578755e-01 ## [7,] 0.131428571 9.462680e-01 ## [8,] 0.142857143 9.345179e-01 ## [9,] 0.180000000 9.286269e-01 ## [10,] 0.202857143 9.230928e-01 ## [11,] 0.222857143 9.121038e-01 ## [12,] 0.225714286 9.008135e-01 ## [13,] 0.271428571 8.897769e-01 ## [14,] 0.280000000 8.791050e-01 ## [15,] 0.325714286 8.736026e-01 ## [16,] 0.360000000 8.625501e-01 ## [17,] 0.371428571 8.517197e-01 ## [18,] 0.385714286 8.411430e-01 ## [19,] 0.462857143 8.205287e-01 ## [20,] 0.500000000 8.050917e-01 ## [21,] 0.522857143 8.002553e-01 ## [22,] 0.542857143 7.904873e-01 ## [23,] 0.545714286 7.806559e-01 ## [24,] 0.591428571 7.711098e-01 ## [25,] 0.600000000 7.520971e-01 ## [26,] 0.691428571 7.424084e-01 ## [27,] 0.705714286 7.377147e-01 ## [28,] 0.725714286 7.287237e-01 ## [29,] 0.751428571 7.195582e-01 ## [30,] 0.771428571 7.107734e-01 ## [31,] 0.782857143 6.926962e-01 ## [32,] 0.842857143 6.836576e-01 ## [33,] 0.862857143 6.751423e-01 ## [34,] 0.865714286 6.665160e-01 ## [35,] 0.965714286 6.580483e-01 ## [36,] 0.980000000 6.537907e-01 ## [37,] 1.000000000 6.497946e-01 ## [38,] 1.002857143 6.416916e-01 ## [39,] 1.011428571 6.256125e-01 ## [40,] 1.045714286 6.174778e-01 ## [41,] 1.071428571 6.095175e-01 ## [42,] 1.140000000 5.940250e-01 ## [43,] 1.182857143 5.865880e-01 ## [44,] 1.185714286 5.790083e-01 ## [45,] 1.285714286 5.716189e-01 ## [46,] 1.300000000 5.533673e-01 ## [47,] 1.322857143 5.465011e-01 ## [48,] 1.331428571 5.395557e-01 ## [49,] 1.345714286 5.322614e-01 ## [50,] 1.365714286 5.253477e-01 ## [51,] 1.411428571 5.183388e-01 ## [52,] 1.422857143 5.115202e-01 ## [53,] 1.482857143 5.045272e-01 ## [54,] 1.551428571 4.979941e-01 ## [55,] 1.560000000 4.916829e-01 ## [56,] 1.605714286 4.851498e-01 ## [57,] 1.620000000 4.788386e-01 ## [58,] 1.642857143 4.697683e-01 ## [59,] 1.651428571 4.578279e-01 ## [60,] 1.685714286 4.547833e-01 ## [61,] 1.711428571 4.487734e-01 ## [62,] 1.731428571 4.428587e-01 ## [63,] 1.742857143 4.368964e-01 ## [64,] 1.802857143 4.308707e-01 ## [65,] 1.825714286 4.252097e-01 ## [66,] 1.871428571 4.196121e-01 ## [67,] 1.962857143 4.142207e-01 ## [68,] 1.971428571 4.089561e-01 ## [69,] 1.985714286 3.979988e-01 ## [70,] 2.005714286 3.928135e-01 ## [71,] 2.031428571 3.820307e-01 ## [72,] 2.051428571 3.769088e-01 ## [73,] 2.062857143 3.715649e-01 ## [74,] 2.100000000 3.690119e-01 ## [75,] 2.142857143 3.640328e-01 ## [76,] 2.191428571 3.538684e-01 ## [77,] 2.245714286 3.491588e-01 ## [78,] 2.280000000 3.441955e-01 ## [79,] 2.305714286 3.393908e-01 ## [80,] 2.351428571 3.348715e-01 ## [81,] 2.371428571 3.304949e-01 ## [82,] 2.382857143 3.260549e-01 ## [83,] 2.420000000 3.216149e-01 ## [84,] 2.442857143 3.194900e-01 ## [85,] 2.462857143 3.066616e-01 ## [86,] 2.465714286 3.021899e-01 ## [87,] 2.511428571 2.981146e-01 ## [88,] 2.520000000 2.940234e-01 ## [89,] 2.565714286 2.918906e-01 ## [90,] 2.600000000 2.876885e-01 ## [91,] 2.625714286 2.837242e-01 ## [92,] 2.691428571 2.797441e-01 ## [93,] 2.740000000 2.756846e-01 ## [94,] 2.782857143 2.720216e-01 ## [95,] 2.785714286 2.682793e-01 ## [96,] 2.831428571 2.573696e-01 ## [97,] 2.840000000 2.537225e-01 ## [98,] 2.885714286 2.500436e-01 ## [99,] 2.931428571 2.463965e-01 ## [100,] 2.945714286 2.392607e-01 ## [101,] 2.965714286 2.358832e-01 ## [102,] 2.991428571 2.324104e-01 ## [103,] 3.022857143 2.290804e-01 ## [104,] 3.082857143 2.240775e-01 ## [105,] 3.102857143 2.209378e-01 ## [106,] 3.160000000 2.177029e-01 ## [107,] 3.240000000 2.145632e-01 ## [108,] 3.242857143 2.114869e-01 ## [109,] 3.265714286 2.085534e-01 ## [110,] 3.285714286 2.026862e-01 ## [111,] 3.311428571 1.996892e-01 ## [112,] 3.342857143 1.968666e-01 ## [113,] 3.380000000 1.880659e-01 ## [114,] 3.402857143 1.867180e-01 ## [115,] 3.471428571 1.840540e-01 ## [116,] 3.540000000 1.761889e-01 ## [117,] 3.571428571 1.736359e-01 ## [118,] 3.585714286 1.697747e-01 ## [119,] 3.651428571 1.673485e-01 ## [120,] 3.742857143 1.623535e-01 ## [121,] 3.745714286 1.599432e-01 ## [122,] 3.791428571 1.553447e-01 ## [123,] 3.800000000 1.530295e-01 ## [124,] 3.845714286 1.506351e-01 ## [125,] 3.882857143 1.483358e-01 ## [126,] 3.891428571 1.439592e-01 ## [127,] 3.905714286 1.416441e-01 ## [128,] 3.925714286 1.395192e-01 ## [129,] 3.951428571 1.372834e-01 ## [130,] 3.971428571 1.352536e-01 ## [131,] 4.042857143 1.330653e-01 ## [132,] 4.062857143 1.310991e-01 ## [133,] 4.165714286 1.269762e-01 ## [134,] 4.200000000 1.240506e-01 ## [135,] 4.202857143 1.221001e-01 ## [136,] 4.245714286 1.202607e-01 ## [137,] 4.271428571 1.184054e-01 ## [138,] 4.291428571 1.148851e-01 ## [139,] 4.302857143 1.131725e-01 ## [140,] 4.362857143 1.114124e-01 ## [141,] 4.382857143 1.097474e-01 ## [142,] 4.385714286 1.079873e-01 ## [143,] 4.485714286 1.063698e-01 ## [144,] 4.500000000 1.048000e-01 ## [145,] 4.520000000 1.009308e-01 ## [146,] 4.522857143 9.934510e-02 ## [147,] 4.531428571 9.785453e-02 ## [148,] 4.591428571 9.617367e-02 ## [149,] 4.611428571 9.473067e-02 ## [150,] 4.660000000 9.311324e-02 ## [151,] 4.705714286 9.171781e-02 ## [152,] 4.805714286 8.894280e-02 ## [153,] 4.842857143 8.824509e-02 ## [154,] 4.851428571 8.558109e-02 ## [155,] 4.865714286 8.418566e-02 ## [156,] 4.885714286 8.293294e-02 ## [157,] 4.911428571 7.893694e-02 ## [158,] 4.942857143 7.765251e-02 ## [159,] 4.980000000 7.636808e-02 ## [160,] 5.022857143 7.511536e-02 ## [161,] 5.071428571 7.383093e-02 ## [162,] 5.125714286 7.267336e-02 ## [163,] 5.162857143 7.019964e-02 ## [164,] 5.171428571 6.910550e-02 ## [165,] 5.185714286 6.785278e-02 ## [166,] 5.205714286 6.672692e-02 ## [167,] 5.231428571 6.552178e-02 ## [168,] 5.262857143 6.445935e-02 ## [169,] 5.322857143 6.327006e-02 ## [170,] 5.400000000 6.122449e-02 ## [171,] 5.445714286 5.905206e-02 ## [172,] 5.460000000 5.806892e-02 ## [173,] 5.482857143 5.714920e-02 ## [174,] 5.491428571 5.621363e-02 ## [175,] 5.525714286 5.576170e-02 ## [176,] 5.571428571 5.485784e-02 ## [177,] 5.582857143 5.205112e-02 ## [178,] 5.620000000 5.102041e-02 ## [179,] 5.642857143 5.016412e-02 ## [180,] 5.665714286 4.930784e-02 ## [181,] 5.711428571 4.845155e-02 ## [182,] 5.780000000 4.761112e-02 ## [183,] 5.802857143 4.721469e-02 ## [184,] 5.811428571 4.642183e-02 ## [185,] 5.871428571 4.472512e-02 ## [186,] 5.902857143 4.321869e-02 ## [187,] 5.962857143 4.240997e-02 ## [188,] 5.982857143 4.172811e-02 ## [189,] 5.985714286 4.093526e-02 ## [190,] 6.031428571 4.022168e-02 ## [191,] 6.085714286 3.950811e-02 ## [192,] 6.100000000 3.796997e-02 ## [193,] 6.122857143 3.728811e-02 ## [194,] 6.145714286 3.660625e-02 ## [195,] 6.165714286 3.527425e-02 ## [196,] 6.211428571 3.457653e-02 ## [197,] 6.222857143 3.387882e-02 ## [198,] 6.282857143 3.354582e-02 ## [199,] 6.302857143 3.291153e-02 ## [200,] 6.351428571 3.229310e-02 ## [201,] 6.405714286 3.053296e-02 ## [202,] 6.440000000 2.988282e-02 ## [203,] 6.451428571 2.926439e-02 ## [204,] 6.485714286 2.864596e-02 ## [205,] 6.531428571 2.809096e-02 ## [206,] 6.542857143 2.753596e-02 ## [207,] 6.602857143 2.696510e-02 ## [208,] 6.622857143 2.644181e-02 ## [209,] 6.625714286 2.593438e-02 ## [210,] 6.671428571 2.542695e-02 ## [211,] 6.760000000 2.490367e-02 ## [212,] 6.762857143 2.442795e-02 ## [213,] 6.771428571 2.398395e-02 ## [214,] 6.785714286 2.300081e-02 ## [215,] 6.805714286 2.209695e-02 ## [216,] 6.831428571 2.165295e-02 ## [217,] 6.900000000 2.122481e-02 ## [218,] 6.942857143 2.040023e-02 ## [219,] 7.000000000 1.909995e-02 ## [220,] 7.045714286 1.888588e-02 ## [221,] 7.080000000 1.847359e-02 ## [222,] 7.105714286 1.806130e-02 ## [223,] 7.171428571 1.769659e-02 ## [224,] 7.182857143 1.733187e-02 ## [225,] 7.220000000 1.690373e-02 ## [226,] 7.242857143 1.676102e-02 ## [227,] 7.265714286 1.577787e-02 ## [228,] 7.311428571 1.542902e-02 ## [229,] 7.320000000 1.515944e-02 ## [230,] 7.425714286 1.484230e-02 ## [231,] 7.445714286 1.423973e-02 ## [232,] 7.471428571 1.393844e-02 ## [233,] 7.491428571 1.363716e-02 ## [234,] 7.502857143 1.301873e-02 ## [235,] 7.562857143 1.268573e-02 ## [236,] 7.585714286 1.238444e-02 ## [237,] 7.631428571 1.160744e-02 ## [238,] 7.640000000 1.133787e-02 ## [239,] 7.685714286 1.102073e-02 ## [240,] 7.720000000 1.073530e-02 ## [241,] 7.765714286 1.046572e-02 ## [242,] 7.791428571 1.021201e-02 ## [243,] 7.822857143 9.783867e-03 ## [244,] 7.860000000 9.649081e-03 ## [245,] 7.902857143 9.411224e-03 ## [246,] 7.905714286 9.189223e-03 ## [247,] 8.005714286 8.967223e-03 ## [248,] 8.042857143 8.650080e-03 ## [249,] 8.051428571 8.491508e-03 ## [250,] 8.065714286 8.190222e-03 ## [251,] 8.085714286 7.984079e-03 ## [252,] 8.131428571 7.762079e-03 ## [253,] 8.142857143 7.571793e-03 ## [254,] 8.222857143 6.874078e-03 ## [255,] 8.225714286 6.699650e-03 ## [256,] 8.271428571 6.541078e-03 ## [257,] 8.280000000 6.208078e-03 ## [258,] 8.340000000 5.779934e-03 ## [259,] 8.362857143 5.637220e-03 ## [260,] 8.371428571 5.478648e-03 ## [261,] 8.385714286 5.320077e-03 ## [262,] 8.431428571 5.177362e-03 ## [263,] 8.462857143 5.018791e-03 ## [264,] 8.522857143 4.796791e-03 ## [265,] 8.542857143 4.669933e-03 ## [266,] 8.545714286 4.400362e-03 ## [267,] 8.682857143 4.273504e-03 ## [268,] 8.691428571 4.178361e-03 ## [269,] 8.725714286 3.805718e-03 ## [270,] 8.751428571 3.678861e-03 ## [271,] 8.771428571 3.567861e-03 ## [272,] 8.965714286 3.441003e-03 ## [273,] 8.980000000 3.298289e-03 ## [274,] 9.000000000 3.219003e-03 ## [275,] 9.011428571 2.933574e-03 ## [276,] 9.025714286 2.838431e-03 ## [277,] 9.071428571 2.489574e-03 ## [278,] 9.102857143 2.315145e-03 ## [279,] 9.162857143 1.966288e-03 ## [280,] 9.231428571 1.887002e-03 ## [281,] 9.285714286 1.601573e-03 ## [282,] 9.322857143 1.411287e-03 ## [283,] 9.411428571 1.347858e-03 ## [284,] 9.502857143 1.094144e-03 ## [285,] 9.505714286 1.030715e-03 ## [286,] 9.605714286 9.831438e-04 ## [287,] 9.642857143 9.514295e-04 ## [288,] 9.651428571 7.135721e-04 ## [289,] 9.685714286 6.342863e-04 ## [290,] 9.925714286 5.867149e-04 ## [291,] 9.985714286 4.281433e-04 ## [292,] 10.051428571 3.964290e-04 ## [293,] 10.062857143 3.647147e-04 ## [294,] 10.100000000 3.171432e-04 ## [295,] 10.260000000 2.854289e-04 ## [296,] 10.511428571 1.902859e-04 ## [297,] 10.520000000 1.744287e-04 ## [298,] 10.565714286 1.427144e-04 ## [299,] 10.645714286 1.347858e-04 ## [300,] 11.022857143 7.135721e-05 ## [301,] 11.082857143 5.550006e-05 ## [302,] 11.571428571 2.378574e-05 #[[1]] #(m1,m2,m3)1 (m1,m2,m3)2 (m1,m2,m3)3 H pval #5.000000000 5.000000000 4.000000000 9.411400000 0.001347858 4.1.2 大样本近似 wtloss &lt;- read.table(&quot;data/wtloss.txt&quot;) kruskal.test(wtloss[,1],wtloss[,2]) ## ## Kruskal-Wallis rank sum test ## ## data: wtloss[, 1] and wtloss[, 2] ## Kruskal-Wallis chi-squared = 9.4322, df = 2, p-value = 0.00895 4.2 4.2 正态记分检验 单样本、双样本正态记分检验的推广 d=wtloss[order(wtloss[,1]),] n1=sum(d[,2]==1) n2=sum(d[,2]==2) n3=sum(d[,2]==3) n=nrow(d) r=rank(d[,1]) w=qnorm(r/(n+1)) z=cbind(d,r,w) nn=sum(sum(w[z[,2]==1])^2/n1,sum(w[z[,2]==2])^2/n2,sum(w[z[,2]==3])^2/n3) (Tstat=(n-1)*nn/sum(w^2)) ## [1] 9.078947 pchisq(Tstat,3-1,low=F) ## [1] 0.01067903 4.3 4.3 Jonckheere-Terpstra检验 单边（有序）的备择假设 注意与Cox-Stuart趋势检验的区分 4.3.1 精确检验 JT.test=function(m1=5,m2=5,m3=4,JTvalue=59){ # this program is for m1=5, m2=5, and m3 can be any integer m&lt;-m1+m2+m3; Jh5=function(m){ a=rep(0,5) for (i in 1:(m-4)){ for (j in (i+1):(m-3)){ for (k in (j+1):(m-2)){ for (l in (k+1):(m-1)){ for (f in (l+1):m){a&lt;-rbind(a,c(i,j,k,l,f))} } } } } a[2:nrow(a),] }; JTid1=Jh5(m1+m2+m3);n1=nrow(JTid1) JTid2=Jh5(m2+m3);n2=nrow(JTid2); const=1:m; JT=rep(0,n1*n2) for (i in 1:n1){ for (j in 1:n2){ temp1&lt;-c(JTid1[i,]); temp2=(const[-temp1])[c(JTid2[j,])]; temp3=const[-c(temp1,temp2)]; JT[j+(i-1)*n2]&lt;-sum(outer(temp2,temp1,&quot;&gt;&quot;))+ sum(outer(temp3,temp1,&quot;&gt;&quot;))+sum(outer(temp3,temp2,&quot;&gt;&quot;)) } } y=JT; pval=(sum(y&gt;=JTvalue))/(n1*n2);hist(y,breaks=min(y):max(y)) z=c(0,hist(y,breaks=min(y):max(y))$counts) list(&quot;(m1,m2,m3)&quot;=c(m1,m2,m3),c(JTvalue,pval), cbind(min(y):max(y),z,rev(cumsum(rev(z)))/(n1*n2)))} JT.test() ## $`(m1,m2,m3)` ## [1] 5 5 4 ## ## [[2]] ## [1] 5.900000e+01 5.272505e-04 ## ## [[3]] ## z ## [1,] 0 0 1.000000e+00 ## [2,] 1 3 1.000000e+00 ## [3,] 2 5 9.999881e-01 ## [4,] 3 10 9.999683e-01 ## [5,] 4 20 9.999286e-01 ## [6,] 5 35 9.998494e-01 ## [7,] 6 60 9.997106e-01 ## [8,] 7 96 9.994727e-01 ## [9,] 8 151 9.990922e-01 ## [10,] 9 226 9.984936e-01 ## [11,] 10 331 9.975976e-01 ## [12,] 11 468 9.962855e-01 ## [13,] 12 650 9.944302e-01 ## [14,] 13 877 9.918534e-01 ## [15,] 14 1162 9.883767e-01 ## [16,] 15 1505 9.837702e-01 ## [17,] 16 1917 9.778039e-01 ## [18,] 17 2393 9.702044e-01 ## [19,] 18 2941 9.607179e-01 ## [20,] 19 3551 9.490589e-01 ## [21,] 20 4226 9.349817e-01 ## [22,] 21 4948 9.182286e-01 ## [23,] 22 5713 8.986133e-01 ## [24,] 23 6499 8.759653e-01 ## [25,] 24 7296 8.502014e-01 ## [26,] 25 8076 8.212779e-01 ## [27,] 26 8824 7.892623e-01 ## [28,] 27 9514 7.542814e-01 ## [29,] 28 10130 7.165652e-01 ## [30,] 29 10647 6.764069e-01 ## [31,] 30 11052 6.341991e-01 ## [32,] 31 11329 5.903858e-01 ## [33,] 32 11471 5.454744e-01 ## [34,] 33 11471 5.000000e-01 ## [35,] 34 11329 4.545256e-01 ## [36,] 35 11052 4.096142e-01 ## [37,] 36 10647 3.658009e-01 ## [38,] 37 10130 3.235931e-01 ## [39,] 38 9514 2.834348e-01 ## [40,] 39 8824 2.457186e-01 ## [41,] 40 8076 2.107377e-01 ## [42,] 41 7296 1.787221e-01 ## [43,] 42 6499 1.497986e-01 ## [44,] 43 5713 1.240347e-01 ## [45,] 44 4948 1.013867e-01 ## [46,] 45 4226 8.177140e-02 ## [47,] 46 3551 6.501832e-02 ## [48,] 47 2941 5.094112e-02 ## [49,] 48 2393 3.928215e-02 ## [50,] 49 1917 2.979560e-02 ## [51,] 50 1505 2.219606e-02 ## [52,] 51 1162 1.622980e-02 ## [53,] 52 877 1.162330e-02 ## [54,] 53 650 8.146615e-03 ## [55,] 54 468 5.569827e-03 ## [56,] 55 331 3.714539e-03 ## [57,] 56 226 2.402360e-03 ## [58,] 57 151 1.506430e-03 ## [59,] 58 96 9.078223e-04 ## [60,] 59 60 5.272505e-04 ## [61,] 60 35 2.893931e-04 ## [62,] 61 20 1.506430e-04 ## [63,] 62 10 7.135721e-05 ## [64,] 63 5 3.171432e-05 ## [65,] 64 2 1.189287e-05 ## [66,] 65 1 3.964290e-06 4.3.2 大样本近似 d=read.table(&quot;data/wtloss.txt&quot;) U=matrix(0,3,3);k=max(d[,2]); for(i in 1:(k-1)){ for(j in (i+1):k){ U[i,j]=sum(outer(d[d[,2]==i,1],d[d[,2]==j,1],&quot;-&quot;)&lt;0)+sum(outer(d[d[,2]==i,1],d[d[,2]==j,1],&quot;-&quot;)==0)/2; } } J=sum(U); ni=NULL; for(i in 1:k) ni=c(ni,sum(d[,2]==i)); N=sum(ni); Z=(J-(N^2-sum(ni^2))/4)/sqrt((N^2*(2*N+3)-sum(ni^2*(2*ni+3)))/72); pnorm(Z,low=F) ## [1] 0.0009566765 双因素问题 4.4 4.5 完全区组设计：Friedman秩和检验 类比于Randomized Block Design Y是连续的 不依赖于正态假设和方差齐性假设 4.4.1 精确检验 Friedman=function(k=3,b=4,W0=0.8125){ perm=function(n=4){ A=rbind(c(1,2),c(2,1)); if (n&gt;=3){ for (i in 3:n){ temp=cbind(rep(i,nrow(A)),A); for (j in (1:(i-2))){ temp=rbind(temp,cbind(A[,1:j],rep(i,nrow(A)),A[,(j+1):(i-1)])) }; temp=rbind(temp,cbind(A,rep(i,nrow(A))));A=temp }; }; A } B=perm(k); # all possible permutations nn=nrow(B); ind=rep(1:nn,each=nn^(b-1)); for (i in 1:(b-1)){ ind=cbind(ind,rep(rep(1:nn,each=nn^(b-1-i)),nn^(i))) }; nn=nrow(ind); y=rep(0,nn); for (i in 1:nn){ R=apply(B[ind[i,],],2,sum); y[i]=12/(b*k*(k+1))*sum(R^2)-3*b*(k+1) }; y0=sort(unique(y)); ycnt=ydnt=NULL; for (i in 1:length(y0)){ ydnt=c(ydnt,length(y[y==y0[i]])); ycnt=c(ycnt,length(y[y&gt;=y0[i]])) }; plot(y0,ydnt/nn,cex=0.5,ylab=&quot;density function&quot;, xlab=&quot;values of the Friedman statistics&quot;); for (i in 1:length(y0)) points(c(y0[i],y0[i]),c(ydnt[i]/nn,0),type=&quot;l&quot;,lwd=2); list(t(cbind(W=y0/b/(k-1),Q=y0,density=ydnt/nn,pvalue=ycnt/nn)), Pvalue=length(y[y&gt;=(b*(k-1)*W0)])/nn)} Friedman() ## [[1]] ## [,1] [,2] [,3] [,4] [,5] [,6] ## W 0.00000000 0.0625000 0.1875000 0.2500000 0.4375000 0.56250000 ## Q 0.00000000 0.5000000 1.5000000 2.0000000 3.5000000 4.50000000 ## density 0.06944444 0.2777778 0.2222222 0.1574074 0.1481481 0.05555556 ## pvalue 1.00000000 0.9305556 0.6527778 0.4305556 0.2731481 0.12500000 ## [,7] [,8] [,9] ## W 0.75000000 0.81250000 1.00000000 ## Q 6.00000000 6.50000000 8.00000000 ## density 0.02777778 0.03703704 0.00462963 ## pvalue 0.06944444 0.04166667 0.00462963 ## ## $Pvalue ## [1] 0.04166667 4.4.2 大样本近似 X=read.table(&quot;data/blead.txt&quot;) friedman.test(as.matrix(X)) ## ## Friedman rank sum test ## ## data: as.matrix(X) ## Friedman chi-squared = 6.5, df = 2, p-value = 0.03877 X=t(X);Y=apply(X,2,rank);R=apply(Y,1,sum);k=nrow(X);b=ncol(X); Q=12/(b*k*(k+1))*sum(R^2)-3*b*(k+1) #Q=12/(b*k*(k+1))*sum((R-mean(R))^2) Q ## [1] 6.5 (pvalue=pchisq(Q,k-1,low=F)) ## [1] 0.03877421 4.5 4.6 Kendall协同系数检验 评估或排序是否一致 区组设计，Y为有序整数（排名或分数） 二元变量的Kendall’s \\(\\tau\\)在多元情况的推广 注意与Friedman秩和检验统计量的联系 d=read.table(&quot;data/airp35.txt&quot;); R=apply(d,2,sum);b=nrow(d);k=ncol(d); S=sum((R-b*(k+1)/2)^2); (W=12*S/b^2/(k^3-k)); ## [1] 0.7333333 (Q=W*b*(k-1)) ## [1] 8.8 Kendall=function(k=5,b=3,W0=0.733){ perm=function(n=4){ A=rbind(c(1,2),c(2,1)); if (n&gt;=3){ for (i in 3:n){ temp=cbind(rep(i,nrow(A)),A); for (j in (1:(i-2))){ temp=rbind(temp,cbind(A[,1:j],rep(i,nrow(A)),A[,(j+1):(i-1)])) }; temp=rbind(temp,cbind(A,rep(i,nrow(A))));A=temp }; };A } B=perm(k); # all possible permutations nn=nrow(B);ind=rep(1:nn,each=nn^(b-1)); for (i in 1:(b-1)){ ind=cbind(ind,rep(rep(1:nn,each=nn^(b-1-i)),nn^(i))) }; nn=nrow(ind);y=rep(0,nn); for (i in 1:nn){ R=apply(B[ind[i,],],2,sum); y[i]=12/(b*k*(k+1))*sum(R^2)-3*b*(k+1) }; y0=sort(unique(y)); ycnt=ydnt=NULL; for (i in 1:length(y0)){ ydnt=c(ydnt,length(y[y==y0[i]])); ycnt=c(ycnt,length(y[y&gt;=y0[i]])) }; w0=y0/b/(k-1); plot(w0,ydnt/nn,cex=0.5,ylab=&quot;density function&quot;,xlab=&quot;Kendall 协同系数&quot;); for (i in 1:length(y0)) points(c(w0[i],w0[i]),c(ydnt[i]/nn,0),type=&quot;l&quot;,lwd=2) list(t(cbind(W=w0,Q=y0,density=ydnt/nn,pvalue=ycnt/nn)), Pvalue=length(y[y&gt;=(b*(k-1)*W0)])/nn) } Kendall() ## [[1]] ## [,1] [,2] [,3] [,4] [,5] [,6] ## W 0.0000000000 0.02222222 0.04444444 0.06666667 0.08888889 0.11111111 ## Q 0.0000000000 0.26666667 0.53333333 0.80000000 1.06666667 1.33333333 ## density 0.0004166667 0.01125000 0.01666667 0.03083333 0.02708333 0.06895833 ## pvalue 1.0000000000 0.99958333 0.98833333 0.97166667 0.94083333 0.91375000 ## [,7] [,8] [,9] [,10] [,11] [,12] ## W 0.13333333 0.15555556 0.17777778 0.20000000 0.22222222 0.24444444 ## Q 1.60000000 1.86666667 2.13333333 2.40000000 2.66666667 2.93333333 ## density 0.01361111 0.06333333 0.04791667 0.03743056 0.03333333 0.05458333 ## pvalue 0.84479167 0.83118056 0.76784722 0.71993056 0.68250000 0.64916667 ## [,13] [,14] [,15] [,16] [,17] [,18] ## W 0.26666667 0.28888889 0.3111111 0.33333333 0.35555556 0.3777778 ## Q 3.20000000 3.46666667 3.7333333 4.00000000 4.26666667 4.5333333 ## density 0.03583333 0.06604167 0.0175000 0.04291667 0.02666667 0.0587500 ## pvalue 0.59458333 0.55875000 0.4927083 0.47520833 0.43229167 0.4056250 ## [,19] [,20] [,21] [,22] [,23] [,24] ## W 0.40000000 0.42222222 0.4444444 0.46666667 0.48888889 0.51111111 ## Q 4.80000000 5.06666667 5.3333333 5.60000000 5.86666667 6.13333333 ## density 0.02083333 0.03541667 0.0375000 0.01708333 0.02333333 0.04041667 ## pvalue 0.34687500 0.32604167 0.2906250 0.25312500 0.23604167 0.21270833 ## [,25] [,26] [,27] [,28] [,29] [,30] ## W 0.533333333 0.55555556 0.5777778 0.6000000 0.62222222 0.64444444 ## Q 6.400000000 6.66666667 6.9333333 7.2000000 7.46666667 7.73333333 ## density 0.009722222 0.03541667 0.0100000 0.0212500 0.01583333 0.01666667 ## pvalue 0.172291667 0.16256944 0.1271528 0.1171528 0.09590278 0.08006944 ## [,31] [,32] [,33] [,34] [,35] [,36] ## W 0.66666667 0.68888889 0.711111111 0.733333333 0.75555556 0.77777778 ## Q 8.00000000 8.26666667 8.533333333 8.800000000 9.06666667 9.33333333 ## density 0.00750000 0.01041667 0.007916667 0.009166667 0.00250000 0.00875000 ## pvalue 0.06340278 0.05590278 0.045486111 0.037569444 0.02840278 0.02590278 ## [,37] [,38] [,39] [,40] [,41] ## W 0.800000000 0.822222222 0.844444444 0.866666667 0.888888889 ## Q 9.600000000 9.866666667 10.133333333 10.400000000 10.666666667 ## density 0.002083333 0.007291667 0.002500000 0.001250000 0.001250000 ## pvalue 0.017152778 0.015069444 0.007777778 0.005277778 0.004027778 ## [,42] [,43] [,44] ## W 0.911111111 9.555556e-01 1.000000e+00 ## Q 10.933333333 1.146667e+01 1.200000e+01 ## density 0.001875000 8.333333e-04 6.944444e-05 ## pvalue 0.002777778 9.027778e-04 6.944444e-05 ## ## $Pvalue ## [1] 0.03756944 4.5.1 大样本近似 d=read.table(&quot;data/airp.txt&quot;);R=apply(d,2,sum); b=nrow(d);k=ncol(d);S=sum((R-b*(k+1)/2)^2); W=12*S/b^2/(k^3-k);pchisq(b*(k-1)*W,k-1,low=F) ## [1] 0.0003320349 4.6 4.7 Cochran检验 二元响应的数据 解决打结的问题 双样本问题McNemar \\(\\chi^2\\)检验的推广 4.6.1 精确检验 Cochran=function(x){ Xpchs=function(n=7,k=5){ #output(n_1,..,n_k)-all possible combination with n_1+...+n_k=n temp=cbind(n:0,0:n); if (k&gt;=3){ for (j in 3:k){ a1=temp[,1:(j-2)];a2=temp[,j-1];temp0=NULL; for (i in 1:length(a2)){ if (j==3) temp0=rbind(temp0,cbind(rep(a1[i],a2[i]+1),a2[i]:0,0:a2[i])) if (j&gt;3) temp0=rbind(temp0,cbind(matrix(rep(a1[i,],a2[i]+1), ncol=j-2,byrow=T),a2[i]:0,0:a2[i])) } temp=temp0 } } temp } Xpchs2=function(n=4,k=2){ #output: all 0 and 1 columns, with n-k 0s and k- 1s columns Xchoose=function(n=4,k=2){ if (k==0) aa=NULL if (k&gt;=1){ aa=matrix(1:n,ncol=1);m=0; if(k&gt;1){ for(i in 2:k){ m=m+1;m1=nrow(aa); aa=cbind(matrix(rep(aa,each=n),ncol=m),rep(1:n,m1)) aa=aa[(aa[,m+1]&gt;aa[,m]),] } } }; aa }; e01=Xchoose(n,k) temp=matrix(0,nrow=nrow(e01),ncol=n); for (j in 1:nrow(temp)){ if (k==1) temp[j,e01[j]]=1 if (k&gt;1) temp[j,e01[j,]]=1 }; temp } n=nrow(x);k=ncol(x); L=apply(x,1,sum);R=apply(x,2,sum);N=sum(R); Q0=(k*(k-1)*sum((R-mean(R))^2))/(k*N-sum(L^2)); Ni=NULL; for (i in 1:k-1) Ni=c(Ni,sum(L==i)); Ni=Ni[-1]; eye0=Xpchs2(k,1);temp0=Xpchs(Ni[1],nrow(eye0));Ri0=temp0%*%eye0; prob0=factorial(Ni[1])/apply(factorial(temp0),1,prod)*(1/nrow(eye0))^(Ni[1]); if (length(Ni)&gt;1){ for (i in 2:length(Ni)){ eye1=Xpchs2(k,i); temp1=Xpchs(Ni[i],nrow(eye1)); Ri1=temp1%*%eye1; prob1=factorial(Ni[i])/apply(factorial(temp1),1,prod)*(1/nrow(eye1))^(Ni[i]) Ri0=matrix(rep(t(Ri0),nrow(Ri1)),byrow=T,ncol=k)+ matrix(rep(Ri1,each=nrow(Ri0)),ncol=k) prob0=rep(prob0,length(prob1))*rep(prob1,each=length(prob0)) } } xa=k*(k-1)*apply((Ri0-apply(Ri0,1,mean))^2,1,sum)/(k*N-sum(L^2)) nn=length(xa);xa0=sort(unique(xa));xacnt=NULL; for (i in 1:length(xa0)) xacnt=c(xacnt,length(xa[xa==xa0[i]])); plot(xa0,xacnt/nn,cex=0.5,ylab=&quot;density function&quot;,xlab=&quot;value of Cochran statistics&quot;); for (i in 1:length(xa0)){ points(c(xa0[i],xa0[i]),c(xacnt[i]/nn,0),type=&quot;l&quot;,lwd=2) } list(unique(xa),cbind(rbind(t(x),L),c(R,N)),Q=Q0, Exactp=sum(prob0[(xa&gt;=Q0)]),pvalue=pchisq(Q0,k-1,low=F)) } candid=read.table(&quot;data/candid.txt&quot;); Cochran(candid[1:10,]) ## [[1]] ## [1] 20.8235294 20.1176471 17.2941176 14.4705882 15.1764706 11.6470588 ## [7] 9.5294118 18.7058824 15.8823529 12.3529412 10.2352941 7.4117647 ## [13] 6.0000000 3.8823529 18.0000000 6.7058824 8.8235294 4.5882353 ## [19] 3.1764706 1.7647059 1.0588235 0.3529412 13.0588235 ## ## [[2]] ## 1 2 3 4 5 6 7 8 9 10 ## V1 0 1 1 0 0 1 1 1 1 1 7 ## V2 1 1 0 0 0 1 1 1 1 1 7 ## V3 0 1 1 1 1 0 0 0 0 1 5 ## V4 0 0 0 0 1 1 0 0 1 0 3 ## L 1 3 2 1 2 3 2 2 3 3 22 ## ## $Q ## [1] 3.882353 ## ## $Exactp ## [1] 0.3203803 ## ## $pvalue ## [1] 0.2744513 4.6.2 大样本近似 x=read.table(&quot;data/candid.txt&quot;);n=apply(x,2,sum);N=sum(n) L=apply(x,1,sum);k=dim(x)[2] (Q=(k*(k-1)*sum((n-mean(n))^2))/(k*N-sum(L^2))) ## [1] 9.352941 (pvalue=pchisq(Q,k-1,low=F)) ## [1] 0.0249484 4.7 4.8 Page检验 备择假设为有序 类比于Jonckheere检验 完全区组设计 4.7.1 精确检验 Page=function(k=3,b=4,L0=55){ perm=function(n=4){ A=rbind(c(1,2),c(2,1)); if (n&gt;=3){ for (i in 3:n){ temp=cbind(rep(i,nrow(A)),A); for (j in (1:(i-2))){ temp=rbind(temp,cbind(A[,1:j],rep(i,nrow(A)),A[,(j+1):(i-1)])) }; temp=rbind(temp,cbind(A,rep(i,nrow(A))));A=temp }; }; A } B=perm(k); # all possible permutations nn=nrow(B);ind=rep(1:nn,each=nn^(b-1)); for (i in 1:(b-1)){ ind=cbind(ind,rep(rep(1:nn,each=nn^(b-1-i)),nn^(i))) }; nn=nrow(ind);y=rep(0,nn); for (i in 1:nn){ R=apply(B[ind[i,],],2,sum); y[i]=sum((1:k)*R) }; y0=sort(unique(y)); ycnt=NULL; for (i in 1:length(y0)) ycnt=c(ycnt, length(y[y==y0[i]])); plot(y0,ycnt/nn,cex=0.5,ylab=&quot;density function&quot;,xlab=&quot;Page检验统计量&quot;); for (i in 1:length(y0)) points(c(y0[i],y0[i]),c(ycnt[i]/nn,0),type=&quot;l&quot;,lwd=2) list(cbind(L=y0,pvalue=ycnt/nn),Pvalue=length(y[y&gt;=L0])/nn) } Page() ## [[1]] ## L pvalue ## [1,] 40 0.0007716049 ## [2,] 41 0.0061728395 ## [3,] 42 0.0185185185 ## [4,] 43 0.0308641975 ## [5,] 44 0.0524691358 ## [6,] 45 0.0925925926 ## [7,] 46 0.1049382716 ## [8,] 47 0.1172839506 ## [9,] 48 0.1527777778 ## [10,] 49 0.1172839506 ## [11,] 50 0.1049382716 ## [12,] 51 0.0925925926 ## [13,] 52 0.0524691358 ## [14,] 53 0.0308641975 ## [15,] 54 0.0185185185 ## [16,] 55 0.0061728395 ## [17,] 56 0.0007716049 ## ## $Pvalue ## [1] 0.006944444 4.7.2 大样本近似 d=read.table(&quot;data/blead1.txt&quot;);rd=apply(d,1,rank) R=apply(rd,1,sum);(L=sum(R*1:length(R)));k=dim(d)[2];b=dim(d)[1] ## [1] 55 m=b*k*(k+1)^2/4;s=sqrt(b*(k^3-k)^2/144/(k-1));Z=(L-m)/s pnorm(Z,low=F) ## [1] 0.006664164 #library(concord) #page.trend.test(d) 4.8 4.9 Durbin检验 不完全区组设计 与Friedman检验相似 4.8.1 精确检验 Durbin=function(k=4,t=3,b=4,r=3,D0=6.75){ B=cbind(c(1,2,3),c(1,3,2),c(2,1,3),c(2,3,1),c(3,1,2),c(3,2,1)) nn=6^b; Numfunc=function(r,b,nnum){ ind=rep(0,b);temp=nnum; for (i in 1:b){ ind[i]=floor(temp/(6^(b-i))) temp=temp-ind[i]*6^(b-i) }; ind }; y=0;for (i in 0:(nn-1)){ A=B[,Numfunc(r,b,i)+1] R=c(sum(A[1,1:3]),sum(A[2,1:2])+A[1,4],A[3,1]+sum(A[2,3:4]),sum(A[3,2:4])) y=c(y,12*(k-1)/(r*k*(t^2-1))*sum((R-r*(t+1)/2)^2)) }; y=y[2:length(y)]; pvalue=sum(y&gt;=D0)/nn;y0=sort(unique(y)); ycnt=NULL; for (i in 1:length(y0)) ycnt=c(ycnt, length(y[y==y0[i]])); plot(y0,ycnt/nn,cex=0.5,ylab=&quot;density function&quot;,xlab=&quot;Durbin检验统计量&quot;); for (i in 1:length(y0)) points(c(y0[i],y0[i]),c(ycnt[i]/nn,0),type=&quot;l&quot;,lwd=2) list(cbind(&quot;k&quot;=k,&quot;b&quot;=b,&quot;r&quot;=r,&quot;t&quot;=t,&quot;pvalue&quot;=pvalue),cbind(y0,ycnt)) } Durbin() ## [[1]] ## k b r t pvalue ## [1,] 4 4 3 3 0.07407407 ## ## [[2]] ## y0 ycnt ## [1,] 0.00 24 ## [2,] 0.75 264 ## [3,] 1.50 120 ## [4,] 2.25 288 ## [5,] 3.00 96 ## [6,] 3.75 144 ## [7,] 4.50 48 ## [8,] 5.25 192 ## [9,] 6.00 24 ## [10,] 6.75 72 ## [11,] 7.50 24 4.8.2 大样本近似 d=read.table(&quot;data/mater.txt&quot;); k=max(d[,2]);b=max(d[,3]);t=length(d[d[,3]==1,1]); r=length(d[d[,2]==1,1]); R=d;for(i in 1:b) R[d[,3]==i,1]=rank(d[d[,3]==i,1]); RV=NULL;for(i in 1:k) RV=c(RV,sum(R[R[,2]==i,1])); D=12*(k-1)/(r*k*(t^2-1))*sum((RV-r*(t+1)/2)^2); pvalue.chi=pchisq(D,k-1,low=F) A=sum(R[,1]^2);C=b*t*(t+1)^2/4; (D=(k-1)*sum((RV-r*(t+1)/2)^2)/(A-C)); ## [1] 6.75 (pvalue.chi=pchisq(D,k-1,low=F)) ## [1] 0.08030773 "],["尺度参数.html", "第 5 章 尺度参数 5.1 5.1 两独立样本的Siegel-Tukey方差检验 5.2 5.2 两样本尺度参数的Mood检验 5.3 5.3 Ansari-Bradley检验 5.4 5.4 Fligner-Killeen检验 5.5 5.5 两样本尺度的平方秩检验 5.6 5.6 多样本尺度的平方秩检验", " 第 5 章 尺度参数 5.1 5.1 两独立样本的Siegel-Tukey方差检验 假设两总体的位置参数相等，实践中若中位数不等，做平移使之相等 取秩时，“首尾交替” 与Wilcoxon秩和统计量有关 x=read.table(&quot;data/salary.txt&quot;) y=x[x[,2]==2,1];x=x[x[,2]==1,1]; x1=x-median(outer(x,y,&quot;-&quot;)) ##平移 xy=cbind(c(x1,y),c(rep(1,length(x)),rep(2,length(y)))) xy1=xy[order(xy[,1]),] z=xy[,1] ##平移后的数据 n=length(z) a1=2:3;b=2:3; for(i in seq(1,n,2)){b=b+4;a1=c(a1,b)} a2=c(1,a1+2);z=NULL; for(i in 1:n) z=c(z,(i-floor(i/2))) b=1:2; for(i in seq(1,(n+2-2),2)){ if(z[i]/2!=floor(z[i]/2)){ z[i:(i+1)]=b; b=b+2 } } zz=cbind(c(0,0,z[1:(n-2)]),z[1:n]) if(n==1) R=1; if(n==2) R=c(1,2); if(n&gt;2) R=c(a2[1:zz[n,1]],rev(a1[1:zz[n,2]])) xy2=cbind(xy1,R); Wx=sum(xy2[xy2[,2]==1,3]); Wy=sum(xy2[xy2[,2]==2,3]); nx=length(x);ny=length(y); Wxy=Wy-0.5*ny*(ny+1); Wyx=Wx-0.5*nx*(nx+1) (pvalue=pwilcox(Wyx,nx,ny)) ## [1] 0.02428558 sample region rank 9343 1 1 9783 1 4 9956 1 5 10258 1 8 10276 2 9 10374 1 12 10533 2 13 10633 2 16 10827 1 17 10837 2 20 10940 1 21 11209 2 24 11393 2 25 11864 2 28 12032 1 29 12040 2 32 12398 1 31 12552 1 30 12642 2 27 12675 2 26 12749 1 23 13199 2 22 13683 2 19 14049 2 18 14060 1 15 14061 2 14 15951 1 11 16079 1 10 16079 2 7 16441 1 6 17498 1 3 19723 1 2 5.2 5.2 两样本尺度参数的Mood检验 假设两总体的位置参数相等，实践中若中位数不等，做平移使之相等 取秩时，1234…按顺序取秩 x=read.table(&quot;data/salary.txt&quot;) y=x[x[,2]==2,1]; x=x[x[,2]==1,1]; m=length(x);n=length(y) x1=x-median(outer(x,y,&quot;-&quot;)) xy=cbind(c(x1,y),c(rep(1,length(x)),rep(2,length(y)))) N=nrow(xy);xy1=cbind(xy[order(xy[,1]),],1:N) sample region rank 9343 1 1 9783 1 2 9956 1 3 10258 1 4 10276 2 5 10374 1 6 10533 2 7 10633 2 8 10827 1 9 10837 2 10 10940 1 11 11209 2 12 11393 2 13 11864 2 14 12032 1 15 12040 2 16 12398 1 17 12552 1 18 12642 2 19 12675 2 20 12749 1 21 13199 2 22 13683 2 23 14049 2 24 14060 1 25 14061 2 26 15951 1 27 16079 1 28 16079 2 29 16441 1 30 17498 1 31 19723 1 32 R1=xy1[xy1[,2]==1,3]; M=sum((R1-(N+1)/2)^2) E1=m*(N^2-1)/12; s=sqrt(m*n*(N+1)*(N^2-4)/180) (Z=(M-E1)/s); ## [1] 2.330917 (pvalue=pnorm(Z,low=F)) #单边 ## [1] 0.009878857 2*min(pnorm(Z,low=F),pnorm(Z)) #双边 ## [1] 0.01975771 5.3 5.3 Ansari-Bradley检验 假设两总体的位置参数相等，实践中若中位数不等，做平移使之相等 用X或Y在混合样本中的秩到两个极端值中最近的一个的秩的距离来度量 x=read.table(&quot;data/salary.txt&quot;); y=x[x[,2]==2,1] x=x[x[,2]==1,1]; x1=x-median(outer(x,y,&quot;-&quot;)) ansari.test(x1,y,alt=&quot;greater&quot;) ## Warning in ansari.test.default(x1, y, alt = &quot;greater&quot;): cannot compute exact p- ## value with ties ## ## Ansari-Bradley test ## ## data: x1 and y ## AB = 118.5, p-value = 0.02458 ## alternative hypothesis: true ratio of scales is greater than 1 5.4 5.4 Fligner-Killeen检验 5.4.1 两样本尺度的精确检验 计算|Xij-M|，后求秩 考虑Wilcoxon统计量 x=read.table(&quot;data/salary.txt&quot;) y=x[x[,2]==2,1];x=x[x[,2]==1,1]; m=length(x);n=length(y) y1=y+median(outer(x,y,&quot;-&quot;)); M=median(c(x,y1)) xy=cbind(c(abs(x-M),abs(y1-M)),c(rep(1,length(x)),rep(2,length(y)))) N=nrow(xy); xy=xy[order(xy[,1]),] xy1=cbind(xy,rank(xy[,1],ties.method=&quot;average&quot;)) Wx=sum(xy1[xy1[,2]==1,3]); Wyx=Wx-0.5*m*(m+1); Wxy=m*n-Wyx; Wy=sum(xy1[xy1[,2]==2,3]); (pvalue=pwilcox(Wxy,m,n)) ## [1] 0.03474059 ##课本原结果有误 |Xij-M| region rank 179 1 1.5 179 2 1.5 187 1 3.0 333 1 4.0 355 2 5.0 423 2 6.0 456 2 7.0 530 1 8.0 826 2 9.0 980 2 10.0 1010 2 11.0 1279 1 12.0 1382 2 13.0 1392 1 14.0 1464 2 15.0 1586 2 16.0 1686 2 17.0 1830 2 18.0 1841 1 19.0 1842 2 20.0 1845 1 21.0 1943 2 22.0 1961 1 23.0 2263 1 24.0 2436 1 25.0 2876 1 26.0 3732 1 27.0 3860 1 28.5 3860 2 28.5 4222 1 30.0 5279 1 31.0 7504 1 32.0 5.4.2 多样本尺度的大样本近似 x=read.table(&quot;data/salary.txt&quot;); fligner.test(x[,1],x[,2]) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: x[, 1] and x[, 2] ## Fligner-Killeen:med chi-squared = 4.4713, df = 1, p-value = 0.03447 5.5 5.5 两样本尺度的平方秩检验 绝对离差的秩的平方和 x=read.table(&quot;data/salary.txt&quot;) y=x[x[,2]==2,1];x=x[x[,2]==1,1]; m=length(x);n=length(y) x1=abs(x-mean(x));y1=abs(y-mean(y)); xy1=c(x1,y1);xy0=c(x,y) xyi=c(rep(1,m),rep(2,n)); xy=cbind(xy1,xy0,xyi) xy2=cbind(xy[order(xy[,1]),],1:(m+n),(1:(m+n))^2) T1=sum(xy2[xy2[,3]==1,5]); T2=sum(xy2[xy2[,3]==2,5]) R=xy2[,5];meanR=mean(R); S=sqrt(m*n*(sum(R^2)-(m+n)*meanR^2)/(m+n)/(m+n-1)) Zx=(T1-m*meanR)/S;Zy=(T2-n*meanR)/S; (pvalue=min(pnorm(Zx),pnorm(Zy))) ## [1] 0.006255918 绝对离差 原样本 地区 离差秩 秩的平方 248.8824 10270 1 1 1 297.1333 12642 2 2 4 304.8667 12040 2 3 9 330.1333 12675 2 4 16 445.8824 10073 1 5 25 480.8667 11864 2 6 36 599.8824 9919 1 7 49 854.1333 13199 2 8 64 951.8667 11393 2 9 81 965.8824 9553 1 10 100 1062.1176 11581 1 11 121 1135.8667 11209 2 12 144 1338.1333 13683 2 13 169 1507.8667 10837 2 14 196 1704.1333 14049 2 15 225 1711.8667 10633 2 16 256 1716.1333 14061 2 17 289 1811.8667 10533 2 18 324 2057.8824 8461 1 19 361 2068.8667 10276 2 20 400 2170.8824 8348 1 21 441 2623.8824 7895 1 22 484 2739.8824 7779 1 23 529 2953.1176 13472 1 24 576 3041.8824 7477 1 25 625 3081.1176 13600 1 26 676 3214.8824 7304 1 27 729 3443.1176 13962 1 28 784 3654.8824 6864 1 29 841 3734.1333 16079 2 30 900 4500.1176 15019 1 31 961 6725.1176 17244 1 32 1024 5.6 5.6 多样本尺度的平方秩检验 d=read.table(&quot;data/wtloss.txt&quot;); N=nrow(d); k=max(d[,2]) d2=NULL; for (i in 1:k) d2=rbind(d2,cbind(abs(d[d[,2]==i,1]-mean(d[d[,2]==i,1])),d[d[,2]==i,1],i)) d3=cbind(d2[order(d2[,1]),],1:N,(1:N)^2) Ti=NULL; for(i in 1:k) Ti=c(Ti,sum(d3[d3[,3]==i,5])) ni=NULL; for(i in 1:k) ni=c(ni,nrow(d3[d3[,3]==i,])) T=(N-1)*(sum(Ti^2/ni)-sum(Ti)^2/N)/(sum(d3[,5]^2)-sum(Ti)^2/N) (pvalue=pchisq(T,k-1,low=F)) ## [1] 0.07693023 绝对离差 原样本 生活方式 秩 秩的平方 0.300 5.7 2 1 1 0.300 3.7 1 2 4 0.300 3.7 1 3 9 0.325 7.1 3 4 16 0.400 3.0 1 5 25 0.500 3.9 1 6 36 0.500 6.5 2 7 49 0.700 2.7 1 8 64 0.700 5.3 2 9 81 0.800 5.2 2 10 100 1.275 8.7 3 11 121 1.300 7.3 2 12 144 1.575 9.0 3 13 169 2.525 4.9 3 14 196 "],["相关.html", "第 6 章 相关 6.1 6.1 Spearman秩相关检验 6.2 6.2 Kendall \\(\\tau\\) 相关检验 6.3 6.3 Goodman-Kruskal’s \\(\\gamma\\) 相关检验 6.4 6.4 Somers’d 相关检验 6.5 6.5 Theil非参数回归", " 第 6 章 相关 6.1 6.1 Spearman秩相关检验 d=read.table(&quot;data/DM1.txt&quot;); x=d[,2];y=d[,1]; par(mfrow=c(1,2)) plot(x,y) plot(log(x),log(y)) rx=rank(x);ry=rank(y); (rsd=rbind(rx,ry,(rx-ry)^2)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## rx 4 7 15 8 24 29 13 1.5 16.50 9 10.00 14.00 16.50 30 ## ry 8 4 27 10 25 28 9 2.5 21.00 20 6.50 11.50 18.00 30 ## 16 9 144 4 1 1 16 1.0 20.25 121 12.25 6.25 2.25 0 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## rx 20.50 23 11.00 26 1.50 27 18 25 22 19 6 5.00 ## ry 17.00 24 11.50 26 5.00 23 13 22 15 14 1 6.50 ## 12.25 1 0.25 0 12.25 16 25 9 49 25 25 2.25 ## [,27] [,28] [,29] [,30] ## rx 12 20.50 28 3.00 ## ry 16 19.00 29 2.50 ## 16 2.25 1 0.25 n=length(x) (Rs= 1-6*sum((rx-ry)^2)/(n*(n^2-1))) ## [1] 0.8775306 cor.test(x,y,meth=&quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 10.956, df = 28, p-value = 1.235e-11 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7996123 0.9519271 ## sample estimates: ## cor ## 0.9004762 cor.test(x,y,meth=&quot;spearman&quot;) ## Warning in cor.test.default(x, y, meth = &quot;spearman&quot;): Cannot compute exact p- ## value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: x and y ## S = 550.87, p-value = 1.965e-10 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.8774488 没有打结而且样本量不太大时，精确检验 x=c(4.2,4.3,4.4,4.5,4.7,4.6,5.3);y=c(2.6,2.8,3.1,3.8,3.6,4.0,5.0); cor.test(x,y,exact=T,method=&quot;spearman&quot;) ## ## Spearman&#39;s rank correlation rho ## ## data: x and y ## S = 6, p-value = 0.0123 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.8928571 6.2 6.2 Kendall \\(\\tau\\) 相关检验 d=read.table(&quot;data/CPIESI.txt&quot;); n=nrow(d); x=d[,2];y=d[,1] nc=0;nd=0;n0=0; for(i in 1:(n-1)){ for(j in (i+1):n){ nc=nc+((x[j]-x[i])*(y[j]-y[i])&gt;0); nd=nd+((x[j]-x[i])*(y[j]-y[i])&lt;0); n0=n0+((x[j]-x[i])*(y[j]-y[i])==0) } } K=nc-nd; (tau=K/choose(n,2)) ## [1] 0.4219269 cor.test(x,y,meth=&quot;kendall&quot;) ## ## Kendall&#39;s rank correlation tau ## ## data: x and y ## T = 642, p-value = 4.199e-05 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.4219269 有打结情况，调整后统计量\\(\\tau_b\\) Kendall’s \\(\\tau_b\\)还经常用于列联表数据，度量两个有序变量的相关性 当列联表中行列数目差别较大时，使用Kendall’s \\(\\tau_c\\) xx=read.table(&quot;data/incsat.txt&quot;); x=xx[,1]; y=xx[,2]; w=xx[,3]; n1=max(x);n2=max(y);n=sum(w);q=min(n1,n2); WW=matrix(w,byrow=T,nrow=n1); Dc=n^2-sum((apply(WW,2,sum))^2); Dr=n^2-sum((apply(WW,1,sum))^2); Vij=DD=CC=matrix(0,nrow=n1,ncol=n2) for(i in 1:n1){ for (j in 1:n2){ CC[i,j]=sum((x&gt;i)*(y&gt;j)*w)+sum((x&lt;i)*(y&lt;j)*w) DD[i,j]=sum((x&gt;i)*(y&lt;j)*w)+sum((x&lt;i)*(y&gt;j)*w) Vij[i,j]=Dr*sum(WW[i,])+Dc*sum(WW[,j]) } } nc=sum(WW*CC)/2; nd=sum(WW*DD)/2; taub=2*(nc-nd)/sqrt(Dc*Dr) temp=sum(WW*(2*sqrt(Dc*Dr)*(CC-DD)+taub*Vij)^2)-n^3*taub^2*(Dr+Dc)^2 sigtaub=1/(Dc*Dr)*sqrt(temp); tauc=q*(nc-nd)/(n^2) sigtauc=2*q/((q-1)*n^2)*sqrt(sum(WW*(CC-DD)^2)-(nc-nd)^2*4/n); list(taub=c(taub=taub,sigtaub=sigtaub,CI95=c(taub-1.96*sigtaub,taub+1.96*sigtaub)),tauc=c(tauc=tauc,sigtauc=sigtauc,CI95=c(tauc-1.96*sigtauc,tauc+1.96*sigtauc))) ## $taub ## taub sigtaub CI951 CI952 ## 0.179184127 0.095542482 -0.008079138 0.366447391 ## ## $tauc ## tauc sigtauc CI951 CI952 ## 0.171475530 0.092263333 -0.009360603 0.352311662 6.3 6.3 Goodman-Kruskal’s \\(\\gamma\\) 相关检验 两个有序变量 有大量的打结 xx=read.table(&quot;data/incsat.txt&quot;) x=xx[,1];y=xx[,2];w=xx[,3]; n1=max(x);n2=max(y); WW=matrix(w,byrow=T,nrow=n1); DD=CC=matrix(0,nrow=n1,ncol=n2); for (i in 1:n1){ for (j in 1:n2){ CC[i,j]=sum((x&gt;i)*(y&gt;j)*w)+sum((x&lt;i)*(y&lt;j)*w) DD[i,j]=sum((x&gt;i)*(y&lt;j)*w)+sum((x&lt;i)*(y&gt;j)*w) } } nc=sum(WW*CC)/2; nd=sum(WW*DD)/2; G=(nc-nd)/(nc+nd) ASE=1/(nc+nd)^2*sqrt(sum(WW*(2*nd*CC-2*nc*DD)^2)) pvalue=2*(1-pnorm(G/ASE)); CI95=c(G-1.96*ASE,G+1.96*ASE) list(G=G,ASE=ASE,CI95=CI95,pvalue=pvalue) ## $G ## [1] 0.279714 ## ## $ASE ## [1] 0.145529 ## ## $CI95 ## [1] -0.005522756 0.564950817 ## ## $pvalue ## [1] 0.05459941 6.4 6.4 Somers’d 相关检验 xxx=read.table(&quot;data/incsat.txt&quot;) x=xx[,1];y=xx[,2];w=xx[,3]; n1=max(x);n2=max(y);n=sum(w); WW=matrix(w,byrow=T,nrow=n1) Dc=n^2-sum((apply(WW,2,sum))^2); Dr=n^2-sum((apply(WW,1,sum))^2); Vij=DD=CC=nRi=nCj=matrix(0,nrow=n1,ncol=n2) for (i in 1:n1){ for (j in 1:n2){ CC[i,j]=sum((x&gt;i)*(y&gt;j)*w)+sum((x&lt;i)*(y&lt;j)*w) DD[i,j]=sum((x&gt;i)*(y&lt;j)*w)+sum((x&lt;i)*(y&gt;j)*w) Vij[i,j]=Dr*sum(WW[i,])+Dc*sum(WW[,j]) nRi[i,j]=n-sum(WW[i,]); nCj[i,j]=n-sum(WW[,j]) } } nc=sum(WW*CC)/2;nd=sum(WW*DD)/2; taub=2*(nc-nd)/sqrt(Dc*Dr) temp=sum(WW*(2*sqrt(Dc*Dr)*(CC-DD)+taub*Vij)^2)-n^3*taub^2*(Dr+Dc)^2; sigtaub=1/(Dc*Dr)*sqrt(temp); dCR=2*(nc-nd)/Dr; dRC=2*(nc-nd)/Dc; d=4*(nc-nd)/(Dc+Dr); sigdCR=2/Dr^2*sqrt(sum(WW*(Dr*(CC-DD)-2*(nc-nd)*nRi)^2)) sigdRC=2/Dc^2*sqrt(sum(WW*(Dc*(CC-DD)-2*(nc-nd)*nCj)^2)) sigd=sqrt(2*sigtaub^2/(Dc+Dr)*sqrt(Dc*Dr)); z=1.96; list(dCR=c(dCR=dCR,sigdCR=sigdCR,CI95=c(dCR-z*sigdCR,dCR+z*sigdCR)), dRC=c(dRC=dRC,sigdRC=sigdRC,CI95=c(dRC-z*sigdRC,dRC+z*sigdRC)), d=c(d=d,sigd=sigd,CI95=c(d-z*sigd,d+z*sigd))) ## $dCR ## dCR sigdCR CI951 CI952 ## 0.176536943 0.094526643 -0.008735276 0.361809162 ## ## $dRC ## dRC sigdRC CI951 CI952 ## 0.181871005 0.096832841 -0.007921364 0.371663374 ## ## $d ## d sigd CI951 CI952 ## 0.179164282 0.095537191 -0.008088613 0.366417176 6.5 6.5 Theil非参数回归 类似于最小二乘法 d=read.table(&quot;data/CPIGINI.txt&quot;,header=T); x=d[,1];y=d[,2]; n=nrow(d) s=NULL; for(i in 1:(n-1)){ for(j in (i+1):n){ s=c(s,(y[j]-y[i])/(x[j]-x[i])) } } b=median(s); a=median(y-b*x); e=y-a-b*x; (coef=c(a,b)) ## [1] 43.650000 -1.666667 summary(lm(y~x)) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.371 -5.493 -2.510 3.191 33.420 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 45.0656 3.2988 13.661 3.06e-16 *** ## x -1.4888 0.5742 -2.593 0.0134 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.005 on 38 degrees of freedom ## Multiple R-squared: 0.1503, Adjusted R-squared: 0.128 ## F-statistic: 6.723 on 1 and 38 DF, p-value: 0.01344 example.ci=function(){ d=read.table(&quot;data/CPIGINI.txt&quot;,header=T); x=d[,1];y=d[,2]; TT=function(x,y,alpha){ n=length(x);s=NULL for(i in 1:(n-1)){ for(j in (i+1):n){ s=c(s,(y[j]-y[i])/(x[j]-x[i])); } } b=median(s); a=median(y-b*x); e=y-a-b*x; m=length(s); s=sort(s); z=NULL; for(i in 1:m){z=c(z,cor.test(x,y-s[i]*x,method=&quot;kendall&quot;)$p.value)} for(i in 1:floor(m/2)){ if(z[i]&gt;alpha/2){bound=c(i-1,m-i+2,s[i-1],s[m-(i-2)],z[i-1]);break} } list(nrow(d),coefficient=c(a,b),residual=e,ci=bound[1:4],confid=1-2*bound[5]) } list(TT(x,y,0.05)) } example.ci() ## [[1]] ## [[1]][[1]] ## [1] 40 ## ## [[1]]$coefficient ## [1] 43.650000 -1.666667 ## ## [[1]]$residual ## [1] -1.883333 -3.116667 -3.150000 2.850000 7.650000 5.883333 ## [7] -3.683333 0.350000 14.183333 25.950000 -1.483333 -3.116667 ## [13] 3.750000 -0.450000 -5.250000 35.850000 2.683333 -7.683333 ## [19] 9.650000 -11.083333 -1.650000 -0.350000 -1.250000 -5.383333 ## [25] 3.550000 -8.316667 -3.083333 12.783333 2.816667 9.850000 ## [31] 5.883333 0.750000 1.683333 10.016667 -3.550000 2.016667 ## [37] -2.750000 -4.316667 -2.716667 9.616667 ## ## [[1]]$ci ## [1] 293.0000000 488.0000000 -2.6875000 -0.6969697 ## ## [[1]]$confid ## [1] 0.9538398 6.5.1 几种稳健回归 library(MASS) attach(d) lms=lqs(GINI~CPI,method=&quot;lms&quot;); lms$coefficients ## (Intercept) CPI ## 43.123913 -1.608696 lts=lqs(GINI~CPI,method=&quot;lts&quot;); lts$coefficients ## (Intercept) CPI ## 42.276984 -1.791667 se=lqs(GINI~CPI,method=&quot;S&quot;) se$coefficients ## (Intercept) CPI ## 42.716129 -1.741935 nonpara=function(){ d=read.table(&quot;data/reg.txt&quot;,header=T); x=d[,1];y=d[,2]; TT=function(x,y,alpha){n=length(x);s=NULL for(i in 1:(n-1))for(j in (i+1):n)s=c(s,(y[j]-y[i])/(x[j]-x[i])); b=median(s);a=median(y-b*x); e=y-a-b*x; m=length(s);s=sort(s);z=NULL;for(i in 1:m) z=c(z,cor.test(x,y-s[i]*x,method=&quot;kendall&quot;)$p.value) for (i in 1:floor(m/2)) if (z[i]&gt;alpha/2) {bound=c(i-1,m-i+2,s[i-1],s[m-(i-2)],z[i-1]);break} list(nrow(d),coefficient=c(a,b),residual=e,ci=bound[1:4], confid=1-2*bound[5])} library(MASS) lms&lt;-lqs(y~x,method=&quot;lms&quot;) lts&lt;-lqs(y~x,method=&quot;lts&quot;) se&lt;-lqs(y~x,method=&quot;S&quot;) list(&quot;OLS&quot;=(lm(y~x))$coef, &quot;Theil&quot;=TT(x,y,0.05)$coef, &quot;LMS&quot;=lms$coef, &quot;LTS&quot;=lts$coef, &quot;SE&quot;=se$coefficients)} nonpara() ## $OLS ## (Intercept) x ## 4.8132066 0.2116785 ## ## $Theil ## [1] 5.739194 -0.459464 ## ## $LMS ## (Intercept) x ## 6.0634483 -0.8908046 ## ## $LTS ## (Intercept) x ## 6.2328025 -0.9235669 ## ## $SE ## (Intercept) x ## 6.2083630 -0.9359431 6.5.2 Simple Linear Regression #The data are a sample of 235 Belgian working class households. The response variable is annual household income in Belgian francs and the explanatory variable is the annual food expenditure in Belgian francs. library(Rfit) library(quantreg) ## Loading required package: SparseM ## ## Attaching package: &#39;SparseM&#39; ## The following object is masked from &#39;package:base&#39;: ## ## backsolve data(engel) plot(engel) abline(rfit(foodexp~income,data=engel)) abline(lm(foodexp~income,data=engel),lty=2) legend(&quot;topleft&quot;,c(&#39;R&#39;,&#39;LS&#39;),lty=c(1,2)) fit&lt;-rfit(foodexp~income,data=engel) coef(summary(fit)) ## Estimate Std. Error t.value p.value ## (Intercept) 103.6480433 12.77461534 8.113594 2.818115e-14 ## income 0.5377726 0.01150739 46.732793 2.431145e-120 rs&lt;-rstudent(fit) yhat&lt;-fitted.values(fit) par(mfrow=c(1,2)) qqnorm(rs) plot(yhat,rs) 6.5.3 Multiple Linear Regression #a dataset from Morrison (1983: p.64) (c.f. Hettmansperger and McKean 2011). The response variable is the level of free fatty acid (ffa) in a sample of prepubescent boys. The explanatory variables are age (in months), weight (in pounds), and skin fold thickness fit&lt;-rfit(ffa~age+weight+skin,data=ffa) summary(fit) ## Call: ## rfit.default(formula = ffa ~ age + weight + skin, data = ffa) ## ## Coefficients: ## Estimate Std. Error t.value p.value ## (Intercept) 1.4905899 0.2676129 5.5699 2.401e-06 *** ## age -0.0011337 0.0026178 -0.4331 0.6674769 ## weight -0.0153484 0.0038216 -4.0163 0.0002779 *** ## skin 0.2747982 0.1333516 2.0607 0.0464133 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Multiple R-squared (Robust): 0.3773118 ## Reduction in Dispersion Test: 7.47326 p-value: 0.00049 fitF&lt;-rfit(ffa~age+weight+skin,data=ffa) fitR&lt;-rfit(ffa~skin,data=ffa) drop.test(fitF,fitR) ## ## Drop in Dispersion Test ## F-Statistic p-value ## 1.0838e+01 1.9736e-04 "],["分布检验.html", "第 7 章 分布检验 7.1 Q-Q图 7.2 7.1 Kolmogorov-Smirnov单样本检验 7.3 7.2 Kolmogorov-Smirnov两样本分布检验 7.4 7.3 Pearson \\(\\chi^2\\) 拟合优度检验", " 第 7 章 分布检验 7.1 Q-Q图 x=read.table(&quot;data/ind.txt&quot;) x=x$V1 par(mfrow=c(1,2)) qqplot(qnorm(((1:length(x))-0.5)/20,15,0.04),x) z=(x-mean(x))/sd(x) qqnorm(z);qqline(z) 7.2 7.1 Kolmogorov-Smirnov单样本检验 7.2.1 KS检验 ks.test(x,&quot;pnorm&quot;,15,0.2) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x ## D = 0.33943, p-value = 0.0147 ## alternative hypothesis: two-sided 7.2.2 正态性检验 shapiro.test(x) ## ## Shapiro-Wilk normality test ## ## data: x ## W = 0.97442, p-value = 0.8439 library(nortest) lillie.test(x) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: x ## D = 0.11599, p-value = 0.6847 ad.test(x) ## ## Anderson-Darling normality test ## ## data: x ## A = 0.24208, p-value = 0.7364 cvm.test(x) ## ## Cramer-von Mises normality test ## ## data: x ## W = 0.03417, p-value = 0.7708 pearson.test(x) ## ## Pearson chi-square normality test ## ## data: x ## P = 3.1, p-value = 0.5412 sf.test(x) ## ## Shapiro-Francia normality test ## ## data: x ## W = 0.9683, p-value = 0.6274 library(fBasics) ## Loading required package: timeDate ## Loading required package: timeSeries normalTest(x) ## ## Title: ## Shapiro - Wilk Normality Test ## ## Test Results: ## STATISTIC: ## W: 0.9744 ## P VALUE: ## 0.8439 ## ## Description: ## Wed Aug 3 20:39:09 2022 by user: ksnormTest(x) ## ## Title: ## One-sample Kolmogorov-Smirnov test ## ## Test Results: ## STATISTIC: ## D: 1 ## P VALUE: ## Alternative Two-Sided: &lt; 2.2e-16 ## Alternative Less: &lt; 2.2e-16 ## Alternative Greater: 1 ## ## Description: ## Wed Aug 3 20:39:09 2022 by user: shapiroTest(x) ## ## Title: ## Shapiro - Wilk Normality Test ## ## Test Results: ## STATISTIC: ## W: 0.9744 ## P VALUE: ## 0.8439 ## ## Description: ## Wed Aug 3 20:39:09 2022 by user: jarqueberaTest(x) ## ## Title: ## Jarque - Bera Normalality Test ## ## Test Results: ## STATISTIC: ## X-squared: 0.4222 ## P VALUE: ## Asymptotic p Value: 0.8097 ## ## Description: ## Wed Aug 3 20:39:09 2022 by user: dagoTest(x) ## ## Title: ## D&#39;Agostino Normality Test ## ## Test Results: ## STATISTIC: ## Chi2 | Omnibus: 0.9747 ## Z3 | Skewness: -0.79 ## Z4 | Kurtosis: 0.5922 ## P VALUE: ## Omnibus Test: 0.6142 ## Skewness Test: 0.4295 ## Kurtosis Test: 0.5537 ## ## Description: ## Wed Aug 3 20:39:09 2022 by user: 7.3 7.2 Kolmogorov-Smirnov两样本分布检验 z=read.table(&quot;data/ks2.txt&quot;,header=F); (x=z[z[,2]==1,1]);(y=z[z[,2]==2,1]) ## [1] 5.38 4.38 9.33 3.66 3.72 1.66 0.23 0.08 2.36 1.71 2.01 0.90 1.54 ## [1] 6.67 16.21 11.93 9.85 10.43 13.54 2.40 12.89 9.30 11.92 5.74 14.45 ## [13] 1.99 9.14 2.89 ks.test(x,y) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: x and y ## D = 0.72308, p-value = 0.0004714 ## alternative hypothesis: two-sided 拟合优度\\(\\chi^2\\)检验 7.4 7.3 Pearson \\(\\chi^2\\) 拟合优度检验 Ob=c(490,334,68,16);n=sum(Ob); lambda=c(t(0:3)%*%Ob/n) p=exp(-lambda)*lambda^(0:3)/factorial(0:3) E=p*n; Q=sum((E-Ob)^2/E); pvalue=pchisq(Q,2,low=F) 7.4.1 Goodness-of-Fit Tests for a Single Discrete Random Variable #Suppose we roll a die n = 370 times #and we observe the frequencies (58, 55, 62, 68, 66, 61). #Suppose we are interested in testing to see if the die is fair; #i.e., p(j) ≡ 1/6. x &lt;- c(58,55,62,68,66,61) chifit &lt;- chisq.test(x) chifit ## ## Chi-squared test for given probabilities ## ## data: x ## X-squared = 1.9027, df = 5, p-value = 0.8624 round(chifit$expected,digits=4) ## [1] 61.6667 61.6667 61.6667 61.6667 61.6667 61.6667 round((chifit$residuals)^2,digits=4) ## [1] 0.2180 0.7207 0.0018 0.6505 0.3045 0.0072 #(Birth Rate of Males to Swedish Ministers). #This data is discussed on page 266 of Daniel (1978). #It concerns the number of males in the first seven children #for n = 1334 Swedish ministers of religion. oc&lt;-c(6,57,206,362,365,256,69,13) n&lt;-sum(oc) range&lt;-0:7 phat&lt;-sum(range*oc)/(n*7) pmf&lt;-dbinom(range,7,phat) rbind(range,round(pmf,3)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## range 0.000 1.000 2.00 3.000 4.00 5.000 6.000 7.000 ## 0.006 0.047 0.15 0.265 0.28 0.178 0.063 0.009 test.result&lt;-chisq.test(oc,p=pmf) pchisq(test.result$statistic,df=6,lower.tail=FALSE) ## X-squared ## 0.4257546 round(test.result$expected,1) ## [1] 8.5 63.2 200.6 353.7 374.1 237.4 83.7 12.6 7.4.2 Several Discrete Random Variables #(Type of Crime and Alcoholic Status). #The contingency table, Table 2.1, #contains the frequencies of criminals who committed certain crimes and whether or not they are alcoholics. #We are interested in seeing whether or not the distribution of alcoholic status is the same for each type of crime. #The data were obtained from Kendall and Stuart (1979). c1 &lt;- c(50,88,155,379,18,63) c2 &lt;- c(43,62,110,300,14,144) ct &lt;- cbind(c1,c2) chifit &lt;- chisq.test(ct) chifit ## ## Pearson&#39;s Chi-squared test ## ## data: ct ## X-squared = 49.731, df = 5, p-value = 1.573e-09 (chifit$residuals)^2 #residuals=(observed - expected) / sqrt(expected) ## c1 c2 ## [1,] 0.01617684 0.01809979 ## [2,] 0.97600214 1.09202023 ## [3,] 1.62222220 1.81505693 ## [4,] 1.16680759 1.30550686 ## [5,] 0.07191850 0.08046750 ## [6,] 19.61720859 21.94912045 ct2 &lt;- ct[-6,] chisq.test(ct2) ## ## Pearson&#39;s Chi-squared test ## ## data: ct2 ## X-squared = 1.1219, df = 4, p-value = 0.8908 "],["列联表.html", "第 8 章 列联表 8.1 二维列联表的齐性和独立性的\\(\\chi^2\\)检验 8.2 8.2 低维列联表的Fisher精确检验 8.3 8.3 两个比例的比较 8.4 8.4 Cochran-Mantel-Haenszel估计 8.5 8.5 对数线性模型与高维列联表的独立性", " 第 8 章 列联表 8.1 二维列联表的齐性和独立性的\\(\\chi^2\\)检验 8.1.1 齐性 y=matrix(scan(&quot;data/wid.txt&quot;),3,2,b=T) chisq.test(y) ## ## Pearson&#39;s Chi-squared test ## ## data: y ## X-squared = 1.076, df = 2, p-value = 0.5839 8.1.2 独立性 y=matrix(scan(&quot;data/shop.txt&quot;),3,3,b=T) chisq.test(y) ## ## Pearson&#39;s Chi-squared test ## ## data: y ## X-squared = 18.651, df = 4, p-value = 0.0009203 a=loglin(y,list(1,2)) #fit log-linear model ## 2 iterations: deviation 1.421085e-14 pchisq(a$lrt,a$df,low=F) ## [1] 0.000903918 8.1.3 Independence of Two Discrete Random Variables （例子：吸烟与肺癌） chisq.test(matrix(c(43,13,162,121),2,2),correct=F) ## ## Pearson&#39;s Chi-squared test ## ## data: matrix(c(43, 13, 162, 121), 2, 2) ## X-squared = 7.4688, df = 1, p-value = 0.006278 8.2 8.2 低维列联表的Fisher精确检验 8.2.1 数据为表格形式 x=read.table(&quot;data/stroke.txt&quot;); 1-phyper(34,60,53,50) ## [1] 0.001176454 phyper(15,53,60,50) ## [1] 0.001176454 chisq.test(x) ##different results ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: x ## X-squared = 9.107, df = 1, p-value = 0.002546 fisher.test(x) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: x ## p-value = 0.002242 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 1.508528 8.451155 ## sample estimates: ## odds ratio ## 3.504852 8.2.2 数据为数据框格式 x1=read.table(&quot;data/strokeA.txt&quot;) attach(x1) fisher.test(xtabs(V1~.,x1)) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: xtabs(V1 ~ ., x1) ## p-value = 0.002242 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 1.508528 8.451155 ## sample estimates: ## odds ratio ## 3.504852 8.3 8.3 两个比例的比较 8.3.1 例8.3 关于中风的研究 p1=x[1,1]/sum(x[1,]); p2=x[2,1]/sum(x[2,]); pdif1=p1-p2; se1=sqrt(p1*(1-p1)/sum(x[1,])+p2*(1-p2)/sum(x[2,])) pdifc1=c(p1-p2-1.96*se1,p1-p2+1.96*se1) rr1=p1/p2; ser1=sqrt((1-p1)/x[1,1]+(1-p2)/x[2,1]); rrc1=c(rr1*exp(-1.96*ser1),rr1*exp(1.96*ser1)) or1=(p1/(1-p1))/(p2/(1-p2));seor1=sqrt(sum(1/x)) orc1=c(or1*exp(-1.96*seor1),or1*exp(1.96*seor1)) list(dif=pdif1,difCI=pdifc1,RR=rr1,RRCI=rrc1,OR=or1,ORCI=orc1) ## $dif ## [1] 0.3031746 ## ## $difCI ## [1] 0.1278747 0.4784745 ## ## $RR ## [1] 1.764 ## ## $RRCI ## [1] 1.237586 2.514326 ## ## $OR ## [1] 3.546667 ## ## $ORCI ## [1] 1.613185 7.797522 8.3.2 One-Sample Problems* #(Squeaky Hip Replacements). #As a numerical example, Devore(2012), page 284, #reports on a study of 143 subjects who have obtained ceramic hip replacements. #Ten of the subjects in the study reported that their hip replacements squeaked. #Consider patients who receive such a ceramic hip replacement #and let p denote the true proportion of those whose replacement hips develop a squeak. phat&lt;-10/143 zcv&lt;-qnorm(0.975) phat+c(-1,1)*zcv*sqrt(phat*(1-phat)/143) ## [1] 0.02813069 0.11172945 #(Left-Handed Professional Ball Players). #As an example of this test, #consider testing whether the proportion of left-handed professional baseball players is the same as the proportion of left-handed people in the general population, which is about 0.15. #For our sample we use the dataset baseball that consists of observations on 59 professional baseball players, including throwing hand (‘L’ or ‘R’). library(Rfit) ind&lt;-with(baseball,throw==&#39;L&#39;) prop.test(sum(ind),length(ind),p=0.15,correct=FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: sum(ind) out of length(ind), null probability 0.15 ## X-squared = 5.0279, df = 1, p-value = 0.02494 ## alternative hypothesis: true p is not equal to 0.15 ## 95 percent confidence interval: ## 0.1605598 0.3779614 ## sample estimates: ## p ## 0.2542373 binom.test(sum(ind),59,p=.15) ## ## Exact binomial test ## ## data: sum(ind) and 59 ## number of successes = 15, number of trials = 59, p-value = 0.04192 ## alternative hypothesis: true probability of success is not equal to 0.15 ## 95 percent confidence interval: ## 0.1498208 0.3844241 ## sample estimates: ## probability of success ## 0.2542373 8.3.3 Two-Sample Problems* #(Polio Vaccine). Rasmussen (1992), page 355, #discusses one of the original clinical studies for the efficacy of the Salk polio vaccine which took place in 1954. #The effectiveness of the vaccine was not known and there were fears that it could even cause polio since the vaccine contained live virus. #Children with parental written consent were randomly divided into two groups. #Children in the treatment group (1) were injected with the vaccine while those in the control or placebo group (2) were injected with a biologically inert solution. #Let p1 and p2 denote the true proportions of children who get polio in the treatment and control groups, respectively. #The hypothesis of interest is the two-sided hypothesis (2.18). prop.test(c(57,199),c(200745,201229),correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(57, 199) out of c(200745, 201229) ## X-squared = 78.474, df = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.0008608391 -0.0005491224 ## sample estimates: ## prop 1 prop 2 ## 0.0002839423 0.0009889231 8.4 8.4 Cochran-Mantel-Haenszel估计 \\(2 \\times 2 \\times K\\)列联表 x=read.table(&quot;data/hospital.txt&quot;); tmp=array(c(x[,4]),dim=c(2,2,4),dimnames=list(effect=c(&quot;Y&quot;,&quot;N&quot;), med=c(&quot;A&quot;,&quot;B&quot;),hosptl=c(&quot;I&quot;, &quot;II&quot;,&quot;III&quot;,&quot;IV&quot;))); tab=ftable(. ~ med+effect,tmp); list(tab,mantelhaen.test(tmp)) ## [[1]] ## hosptl I II III IV ## med effect ## A Y 8 11 4 19 ## N 21 10 7 7 ## B Y 2 2 1 2 ## N 35 13 22 4 ## ## [[2]] ## ## Mantel-Haenszel chi-squared test with continuity correction ## ## data: tmp ## Mantel-Haenszel X-squared = 18.674, df = 1, p-value = 1.551e-05 ## alternative hypothesis: true common odds ratio is not equal to 1 ## 95 percent confidence interval: ## 2.849271 18.094337 ## sample estimates: ## common odds ratio ## 7.180227 8.5 8.5 对数线性模型与高维列联表的独立性 x=read.table(&quot;data/wmq.txt&quot;,header=T); xt=xtabs(Count~.,x) a &lt;- loglin(xt,list(1:2,c(1,3))) ## 2 iterations: deviation 1.421085e-14 a ## $lrt ## [1] 1.099333 ## ## $pearson ## [1] 1.099896 ## ## $df ## [1] 3 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Capacity&quot; &quot;Location&quot; pchisq(a$lrt,a$df,low=F) ## [1] 0.7772351 pchisq(a$pearson,a$df,low=F) ## [1] 0.7770992 loglin(xt,list(1:2,c(1,3)),para=T) ## 2 iterations: deviation 1.421085e-14 ## $lrt ## [1] 1.099333 ## ## $pearson ## [1] 1.099896 ## ## $df ## [1] 3 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Capacity&quot; &quot;Location&quot; ## ## ## $param ## $param$`(Intercept)` ## [1] 3.780874 ## ## $param$Capacity ## L M S ## 0.14228407 -0.12635489 -0.01592918 ## ## $param$Area ## N S ## -0.03162251 0.03162251 ## ## $param$Location ## R U ## -0.113156 0.113156 ## ## $param$Capacity.Area ## Area ## Capacity N S ## L 0.11474022 -0.11474022 ## M -0.06421120 0.06421120 ## S -0.05052902 0.05052902 ## ## $param$Capacity.Location ## Location ## Capacity R U ## L 0.25557458 -0.25557458 ## M -0.03440251 0.03440251 ## S -0.22117207 0.22117207 loglin(xt,list(1,2,3)) ## 2 iterations: deviation 0 ## $lrt ## [1] 26.56823 ## ## $pearson ## [1] 27.29357 ## ## $df ## [1] 7 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; ## ## $margin[[2]] ## [1] &quot;Area&quot; ## ## $margin[[3]] ## [1] &quot;Location&quot; loglin(xt,list(1:2,3)) ## 2 iterations: deviation 1.421085e-14 ## $lrt ## [1] 22.80078 ## ## $pearson ## [1] 22.6113 ## ## $df ## [1] 5 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Location&quot; loglin(xt,list(1,2:3)) ## 2 iterations: deviation 0 ## $lrt ## [1] 24.70076 ## ## $pearson ## [1] 24.51553 ## ## $df ## [1] 6 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; ## ## $margin[[2]] ## [1] &quot;Area&quot; &quot;Location&quot; loglin(xt,list(2,c(1,3))) ## 2 iterations: deviation 1.421085e-14 ## $lrt ## [1] 4.866786 ## ## $pearson ## [1] 4.856742 ## ## $df ## [1] 5 ## ## $margin ## $margin[[1]] ## [1] &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Capacity&quot; &quot;Location&quot; loglin(xt,list(1:2,c(1,3))) ## 2 iterations: deviation 1.421085e-14 ## $lrt ## [1] 1.099333 ## ## $pearson ## [1] 1.099896 ## ## $df ## [1] 3 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Capacity&quot; &quot;Location&quot; loglin(xt,list(1:2,2:3)) ## 2 iterations: deviation 2.842171e-14 ## $lrt ## [1] 20.9333 ## ## $pearson ## [1] 20.793 ## ## $df ## [1] 4 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Area&quot; ## ## $margin[[2]] ## [1] &quot;Area&quot; &quot;Location&quot; loglin(xt,list(c(1,3),2:3)) ## 2 iterations: deviation 0 ## $lrt ## [1] 2.999312 ## ## $pearson ## [1] 2.998752 ## ## $df ## [1] 4 ## ## $margin ## $margin[[1]] ## [1] &quot;Capacity&quot; &quot;Location&quot; ## ## $margin[[2]] ## [1] &quot;Area&quot; &quot;Location&quot; "],["密度估计和回归.html", "第 9 章 密度估计和回归 9.1 非参数密度估计 9.2 非参数回归", " 第 9 章 密度估计和回归 9.1 非参数密度估计 9.1.1 一元密度估计 9.1.1.1 核密度估计 par(mfrow=c(2,2)); x=faithful$waiting; library(KernSmooth); ## KernSmooth 2.23 loaded ## Copyright M. P. Wand 1997-2009 w=bkde(x,band=0.3);plot(w,type=&quot;l&quot;,main=&quot;h=0.3&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;); w=bkde(x,band=0.5);plot(w,type=&quot;l&quot;,main=&quot;h=0.5&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;); w=bkde(x,band=1);plot(w,type=&quot;l&quot;,main=&quot;h=1&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;); w=bkde(x, band=2);plot(w,type=&quot;l&quot;,main=&quot;h=2&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) 9.1.1.2 局部多项式密度估计 par(mfrow=c(1,1)); x=faithful$waiting; library(KernSmooth) par(family=&#39;STKaiti&#39;) plot(x=c(30,110),y=c(0,0.04),type =&quot;n&quot;,bty=&quot;l&quot;,xlab=&quot;waiting time (minute)&quot;,ylab =&quot;density&quot;) lines(bkde(x,bandwidth=dpik(x))) lines(locpoly(x,bandwidth=dpik(x)),lty=3) legend(30,0.04,legend = c(&quot;核密度估计&quot;,&quot;局部多项式密度估计&quot;),lty = c(1,3)) 9.1.1.3 k近邻估计 9.1.2 多元密度估计 library(ks); par(mfrow=c(1,2)); fhat&lt;- kde(faithful) plot(fhat, display=&quot;filled.contour2&quot;) points(faithful, cex=0.5, pch=16) plot(fhat, display=&quot;persp&quot;) 9.2 非参数回归 9.2.0.1 滑动平均（k近邻光滑） library(spatstat); library(MASS) X=mcycle[,1]; Y=mcycle[,2]; m=nnwhich(X,k=1:8); z3=z5=z7=z9=Y; for (j in 1:2) z3=cbind(z3,Y[m[,j]]) for (j in 1:4) z5=cbind(z5,Y[m[,j]]) for (j in 1:6) z7=cbind(z7,Y[m[,j]]) for (j in 1:8) z9=cbind(z9,Y[m[,j]]) par(mfrow=c(2,2));mtx=list(&quot;k=3&quot;,&quot;k=5&quot;,&quot;k=7&quot;,&quot;k=9&quot;) plot(X,Y,main=mtx[[1]]);points(X,apply(z3,1,mean),type=&quot;l&quot;,col=&#39;red&#39;) plot(X,Y,main=mtx[[2]]);points(X,apply(z5,1,mean),type=&quot;l&quot;,col=&#39;red&#39;) plot(X,Y,main=mtx[[3]]);points(X,apply(z7,1,mean),type=&quot;l&quot;,col=&#39;red&#39;) plot(X,Y,main=mtx[[4]]);points(X,apply(z9,1,mean),type=&quot;l&quot;,col=&#39;red&#39;) 9.2.0.2 核回归光滑 library(MASS);par(mfrow=c(2,2));X=mcycle[,1];Y=mcycle[,2] bw=list(&quot;lam=1&quot;, &quot;h=2&quot;, &quot;h=3&quot;, &quot;h=5&quot;) plot(X,Y,main=bw[[1]]);lines(ksmooth(X,Y,&quot;normal&quot;,bandwidth=1),col=&#39;red&#39;) plot(X,Y,main=bw[[2]]);lines(ksmooth(X,Y,&quot;normal&quot;,bandwidth=2),col=&#39;red&#39;) plot(X,Y,main=bw[[3]]);lines(ksmooth(X,Y,&quot;normal&quot;,bandwidth=3),col=&#39;red&#39;) plot(X,Y,main=bw[[4]]);lines(ksmooth(X,Y,&quot;normal&quot;,bandwidth=5),col=&#39;red&#39;) 9.2.0.3 Loess局部加权多项式回归 Loess: locally weighted polynomial regression Lowess: locally weighted scatter plot smoothing 9.2.0.4 光滑样条 smoothing spline library(MASS);par(mfrow=c(2,2)) bw=list(&quot;lambda=0.01&quot;, &quot;lambda=0.001&quot;, &quot;lambda=0.0001&quot;, &quot;lambda=0.000001&quot;) plot(X,Y,main=bw[[1]]);lines(smooth.spline(X,Y,lambda=0.01),col=&#39;red&#39;) plot(X,Y,main=bw[[2]]);lines(smooth.spline(X,Y,lambda=0.001),col=&#39;red&#39;) plot(X,Y,main=bw[[3]]);lines(smooth.spline(X,Y,lambda=0.0001),col=&#39;red&#39;) plot(X,Y,main=bw[[4]]);lines(smooth.spline(X,Y,lambda=0.000001),col=&#39;red&#39;) 9.2.0.5 Firedman超光滑法 Friedman’s Supersmoother library(MASS); attach(mcycle); par(mfrow=c(2,2)); plot(accel~times,mcycle,main=&quot;Lowess&quot;); lines(lowess(mcycle,f=.1),col=&#39;red&#39;); fit1=loess(accel~times,mcycle,span=.15); pred1=predict(fit1,data.frame(times=seq(0,60,length=160)),se=TRUE); plot(accel~times,mcycle,main=&quot;Loess&quot;); lines(seq(0,60,length=160),pred1$fit,col=&#39;red&#39;); plot(accel~times,mcycle,main=&quot;Friedman&#39;s SuperSmoother&quot;); lines(supsmu(times,accel),col=&#39;red&#39;) plot(accel~times,mcycle,main=&quot;Smoothing Spline&quot;); lines(ksmooth(times,accel,&quot;normal&quot;,bandwidth=2),col=&#39;red&#39;) "],["bootstrap.html", "第 10 章 Bootstrap 10.1 Percentile Bootstrap Confidence Intervals 10.2 Bootstrap Tests of Hypotheses", " 第 10 章 Bootstrap x&lt;-rnorm(25,30,5) B&lt;-1000 # number of bootstrap samples to obtain xbar&lt;-rep(0,B) for( i in 1:B ){ xbs&lt;-sample(x,length(x),replace=TRUE) xbar[i]&lt;-mean(xbs) } se.xbar&lt;-sd(xbar) se.xbar ## [1] 0.8517539 tcv&lt;-qt(0.975,length(x)-1) mean(x)+c(-1,1)*tcv*se.xbar ## [1] 29.82139 33.33726 mean(x)+c(-1,1)*tcv*sd(x)/sqrt(length(x)) ## [1] 29.75436 33.40429 10.1 Percentile Bootstrap Confidence Intervals quantile(xbar,probs=c(0.025,0.975),type=1) ## 2.5% 97.5% ## 29.88558 33.17631 m&lt;-0.025*1000 sort(xbar)[c(m,B-m)] ## [1] 29.88558 33.17631 library(&quot;boot&quot;) bsxbar&lt;-boot(x,function(x,indices) mean(x[indices]), B) boot.ci(bsxbar) ## Warning in boot.ci(bsxbar): bootstrap variances needed for studentized intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 1000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bsxbar) ## ## Intervals : ## Level Normal Basic ## 95% (29.97, 33.18 ) (30.03, 33.24 ) ## ## Level Percentile BCa ## 95% (29.92, 33.13 ) (29.85, 33.08 ) ## Calculations and Intervals on Original Scale quantile(bsxbar$t,probs=c(0.025,0.975),type=1) ## 2.5% 97.5% ## 29.92193 33.12238 10.2 Bootstrap Tests of Hypotheses 10.2.1 Nursery School Intervention school&lt;-c(82,69,73,43,58,56,76,65) home&lt;-c(63,42,74,37,51,43,80,62) d &lt;- school - home dpm&lt;-c(d,-d) n&lt;-length(d) B&lt;-5000 dbs&lt;-matrix(sample(dpm,n*B,replace=TRUE),ncol=n) wilcox.teststat&lt;-function(x) wilcox.test(x)$statistic bs.teststat&lt;-apply(dbs,1,wilcox.teststat) mean(bs.teststat&gt;=wilcox.teststat(d)) #[1] 0.0238 10.2.2 Bootstrap test for sample mean x&lt;-rnorm(25,1.5,1) thetahat&lt;-mean(x) x0&lt;-x-thetahat+1 #theta0 is 1 mean(x0) # notice H0 is true ## [1] 1 B&lt;-5000 xbar&lt;-rep(0,B) for( i in 1:B ) { xbs&lt;-sample(x0,length(x),replace=TRUE) xbar[i]&lt;-mean(xbs) } mean(xbar&gt;=thetahat) ## [1] 0.0092 library(Rfit) boot.rfit&lt;-function(data,indices){ data&lt;-data[indices,] fit&lt;-rfit(weight~height,data=data,tau=&#39;N&#39;) coefficients(fit)[2] } bb.boot&lt;-boot(data=baseball,statistic=boot.rfit,R=1000) bb.boot ## ## ORDINARY NONPARAMETRIC BOOTSTRAP ## ## ## Call: ## boot(data = baseball, statistic = boot.rfit, R = 1000) ## ## ## Bootstrap Statistics : ## original bias std. error ## t1* 5.714286 -0.1405727 0.7748821 plot(bb.boot) boot.ci(bb.boot,type=&#39;perc&#39;,index=1) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 1000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bb.boot, type = &quot;perc&quot;, index = 1) ## ## Intervals : ## Level Percentile ## 95% ( 3.75, 7.00 ) ## Calculations and Intervals on Original Scale "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
